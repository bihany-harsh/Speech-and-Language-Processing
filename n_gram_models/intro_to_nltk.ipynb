{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import pad_sequence, ngrams, everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends, flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [[\"A\", \"B\", \"C\"], [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'B'), ('B', 'C')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(text[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'A'), ('A', 'B'), ('B', 'C'), ('C', '</s>')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentence = list(pad_sequence(text[0], pad_left=True, left_pad_symbol=\"<s>\", pad_right=True, right_pad_symbol=\"</s>\", n=2))\n",
    "list(ngrams(padded_sentence, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', '<s>', 'A'),\n",
       " ('<s>', 'A', 'B'),\n",
       " ('A', 'B', 'C'),\n",
       " ('B', 'C', '</s>'),\n",
       " ('C', '</s>', '</s>')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentence = list(pad_sequence(text[0], pad_left=True, left_pad_symbol=\"<s>\", pad_right=True, right_pad_symbol=\"</s>\", n=3))\n",
    "list(ngrams(padded_sentence, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>',),\n",
       " ('<s>', 'A'),\n",
       " ('A',),\n",
       " ('A', 'B'),\n",
       " ('B',),\n",
       " ('B', 'C'),\n",
       " ('C',),\n",
       " ('C', '</s>'),\n",
       " ('</s>',)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_bigrams = list(pad_both_ends(text[0], n=2))\n",
    "list(everygrams(padded_bigrams, max_len=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the function that does everthing for us.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "train, vocab = padded_everygram_pipeline(order=2, text=text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid re-creating the text in memory, both train and vocab are lazy iterators. They are evaluated on demand at the training time.\n",
    "\n",
    "To understand the output of the ''padded_everygram_pipeline'':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>',), ('<s>', 'A'), ('A',), ('A', 'B'), ('B',), ('B', 'C'), ('C',), ('C', '</s>'), ('</s>',)]\n",
      "\n",
      "[('<s>',), ('<s>', 'A'), ('A',), ('A', 'B'), ('B',), ('B', 'C'), ('C',), ('C', 'D'), ('D',), ('D', 'E'), ('E',), ('E', 'F'), ('F',), ('F', '</s>'), ('</s>',)]\n",
      "\n",
      "#############\n",
      "['<s>', 'A', 'B', 'C', '</s>', '<s>', 'A', 'B', 'C', 'D', 'E', 'F', '</s>']\n"
     ]
    }
   ],
   "source": [
    "training_ngrams, padded_sentences = padded_everygram_pipeline(order=2, text=text)\n",
    "for ngramlize_sentence in training_ngrams:\n",
    "    print(list(ngramlize_sentence))\n",
    "    print()\n",
    "print(\"#############\")\n",
    "print(list(padded_sentences))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLTK Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from nltk import word_tokenize, sent_tokenize \n",
    "    # Testing whether it works. \n",
    "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
    "except: \n",
    "    import re\n",
    "    from nltk.tokenize import ToktokTokenizer\n",
    "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "    toktok = ToktokTokenizer()\n",
    "    word_tokenize = word_tokenize = toktok.tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOME REAL DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "with io.open(os.path.join(\"data\", \"language-never-random.txt\"), encoding='utf8') as fin:\n",
    "    text = fin.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Language is never, ever, ever, random\n",
      "\n",
      "                                                               ADAM KILGARRIFF\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Abstract\n",
      "Language users never choose words randomly, and language is essentially\n",
      "non-random. Statistical hypothesis testing uses a null hypothesis, which\n",
      "posits randomness. Hence, when we look at linguistic phenomena in cor-\n",
      "pora, the null hypothesis will never be true. Moreover, where there is enough\n",
      "data, we shall (almost) always be able to establish \n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-gram Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a N-gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# FIRSTLY a simple Maximum Likelihood Estimator\n",
    "from nltk.lm import MLE\n",
    "model = MLE(order=n)\n",
    "print(len(model.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429\n"
     ]
    }
   ],
   "source": [
    "model.fit(text=train_data, vocabulary_text=padded_sents)\n",
    "print(len(model.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('language', 'is', 'never', 'random', '<UNK>', '.')\n"
     ]
    }
   ],
   "source": [
    "# trying the model vocab\n",
    "print(model.vocab.lookup(\"language is never random lah .\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "11\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# assessing the counts\n",
    "print(model.counts[\"language\"]) # count('language')\n",
    "print(model.counts[[\"language\"]][\"is\"]) # count('is' | 'language')\n",
    "print(model.counts[[\"language\", \"is\"]][\"never\"]) # count('never' | 'language is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003916040100250626\n",
      "0.44\n",
      "0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "print(model.score('language')) # P('language')\n",
    "print(model.score('is', 'language'.split()))  # P('is'|'language')\n",
    "print(model.score('never', 'language is'.split()))  # P('never'|'language is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'system', 'â€¦', 'the', 'performance', 'of', 'the', 'european', 'chapter', 'of', 'the', 'error', 'term', 'is', 'very', 'high', '.', '</s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(20, random_seed=34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', the sum is over the four cells of the conference of the cells in the empirical linguistics.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making human readable sentences\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "detokenize = TreebankWordDetokenizer().detokenize\n",
    "\n",
    "def generate_sent(model, num_words, random_seed=42):\n",
    "    content = []\n",
    "    for token in model.generate(num_words, random_seed=random_seed):\n",
    "        if token == \"<s>\":\n",
    "            continue\n",
    "        if token == \"</s>\":\n",
    "            break\n",
    "        content.append(token)\n",
    "    return detokenize(content)\n",
    "\n",
    "generate_sent(model, 20, random_seed=67)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

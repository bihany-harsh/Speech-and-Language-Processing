{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6caacbd",
   "metadata": {},
   "source": [
    "*The following is a referenced implementation of a CRF (conditional random fields) based discriminative markov model for Part of Speech tagging*<br/>\n",
    "*Several improvements are possible: word preprocessing, handling OOV words etc.*<br/>\n",
    "*The current state of the art transformers do POS tagging with an accuracy of ~98%*<br/>\n",
    "*I was able to acheive a decent matching (96.7% on 20% held out test corpus) as well with this statistical model*<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73994ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23d2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nltk.corpus.treebank\n",
    "# tagged_sents = list(dataset.tagged_sents(tagset=\"universal\"))\n",
    "tagged_sents = list(dataset.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71852be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word_tag_list is: 100676 long\n",
      "Vocab_size: 12408, the number of tags: 46\n"
     ]
    }
   ],
   "source": [
    "# build the vocab\n",
    "word_tag_list = [pair for sent in tagged_sents for pair in sent]\n",
    "print(f\"The word_tag_list is: {len(word_tag_list)} long\")\n",
    "vocab = list(set([pair[0] for pair in word_tag_list]))\n",
    "vocab_size = len(vocab)\n",
    "tags = list(set([pair[1] for pair in word_tag_list]))\n",
    "num_tags = len(tags)\n",
    "word_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "index_to_word = {i:word for i, word in enumerate(vocab)}\n",
    "tag_to_index = {tag:i for i, tag in enumerate(tags)}\n",
    "tag_to_index = {i:tag for tag, i in enumerate(tags)}\n",
    "print(f\"Vocab_size: {vocab_size}, the number of tags: {num_tags}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24ae9626",
   "metadata": {},
   "source": [
    "**[reference](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#let-s-use-conll-2002-data-to-build-a-ner-system)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b02fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9093 will\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index[\"will\"], index_to_word[word_to_index[\"will\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86fefd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WP$', '-LRB-', 'RBR', 'NNS', 'IN', '$', 'VBD', '-NONE-', 'CC', 'PRP$', 'JJ', 'RBS', 'SYM', 'VBZ', 'NN', 'RB', 'WDT', ',', 'JJS', \"''\", 'TO', ':', '#', 'CD', 'VBN', 'DT', 'LS', 'JJR', 'MD', 'VBG', 'RP', '-RRB-', 'PRP', 'EX', 'VB', 'POS', '``', 'WP', '.', 'PDT', 'UH', 'FW', 'NNPS', 'VBP', 'WRB', 'NNP']\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f11c900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3131 783\n"
     ]
    }
   ],
   "source": [
    "n = len(tagged_sents)\n",
    "import random\n",
    "random.shuffle(tagged_sents)\n",
    "train_data = tagged_sents[:int(0.8*n)]\n",
    "test_data = tagged_sents[int(0.8*n):]\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97670cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('very', 'RB'),\n",
       " ('surprised', 'VBN'),\n",
       " ('if', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('departure', 'NN'),\n",
       " ('signals', 'VBZ'),\n",
       " ('any', 'DT'),\n",
       " ('change', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('strategy', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('change', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('profit', 'NN'),\n",
       " ('expectations', 'NNS'),\n",
       " ('.', '.'),\n",
       " (\"''\", \"''\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f28bff66",
   "metadata": {},
   "source": [
    "**Developing features for out text** <br/>\n",
    "Features can be: <br/>\n",
    "1. Capital Letters {generally proper noun, beginning of sentences} <br/>\n",
    "2. First word {determiners, and propositions} <br/>\n",
    "3. Last word <br/>\n",
    "4. Number and alphabets <br/>\n",
    "5. Contains hyphen <br/>\n",
    "6. Prefixes and suffiexes <br/>\n",
    "etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d6c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_word_features(sentence, index):\n",
    "  \"\"\"\n",
    "    Parameters:\n",
    "      ~sentence: [list of tuples: (word, tag)]~\n",
    "      sentence: [list of words]\n",
    "      index: position of word in the list (sentence)\n",
    "    Returns:\n",
    "      the feature dict\n",
    "  \"\"\"\n",
    "#   word = sentence[index][0]\n",
    "#   tag = sentence[index][1]\n",
    "  word = sentence[index]\n",
    "  features = {\n",
    "    'bias': 1.0,\n",
    "    'BOS': int(index==0),\n",
    "    'EOS':int(index==len(sentence)-1),\n",
    "    'is_complete_capital': int(word.upper()==word),\n",
    "    'prev_word':'' if index==0 else sentence[index-1],\n",
    "    'next_word':'' if index==len(sentence)-1 else sentence[index+1],\n",
    "    'word.lower()': word.lower(),\n",
    "    'suffix_4': word[-4:], # suffixes\n",
    "    'suffix_3': word[-3:], \n",
    "    'suffix_2': word[-2:],\n",
    "    'prefix_1': word[0],\n",
    "    'prefix_2': word[:2],\n",
    "    'prefix_3': word[:3],\n",
    "    'prefix_4': word[:4],\n",
    "    'word.isupper()': word.isupper(),\n",
    "    'word.istitle()': word.istitle(),\n",
    "    'word.isdigit()': word.isdigit(),\n",
    "    'is_alphanumeric': int(bool((re.match('^(?=.*[0-9]$)(?=.*[a-zA-Z])',word)))),\n",
    "#     'postag': tag,\n",
    "    'word_has_hyphen': 1 if '-' in word else 0,\n",
    "  }\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c03b4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_from_tagged_sent(tagged_sent):\n",
    "  return [word for word, _ in tagged_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04c4ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(tagged_sentences):\n",
    "  \"\"\"\n",
    "    Parameters:\n",
    "      tagged_sentences: [list of tuples: (word, tag)]\n",
    "    Returns:\n",
    "      X: [feature set]\n",
    "      y: [target tags]\n",
    "  \"\"\"\n",
    "  X, y = [], []\n",
    "  for sentence in tagged_sentences:\n",
    "    X.append([get_word_features(sent_from_tagged_sent(sentence), index) for index in range(len(sentence))])\n",
    "    y.append([tag for _, tag in sentence]) \n",
    "    \n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e6b5653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[{'bias': 1.0,\n",
       "    'BOS': 1,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 1,\n",
       "    'prev_word': '',\n",
       "    'next_word': 'would',\n",
       "    'word.lower()': 'i',\n",
       "    'suffix_4': 'I',\n",
       "    'suffix_3': 'I',\n",
       "    'suffix_2': 'I',\n",
       "    'prefix_1': 'I',\n",
       "    'prefix_2': 'I',\n",
       "    'prefix_3': 'I',\n",
       "    'prefix_4': 'I',\n",
       "    'word.isupper()': True,\n",
       "    'word.istitle()': True,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'I',\n",
       "    'next_word': 'be',\n",
       "    'word.lower()': 'would',\n",
       "    'suffix_4': 'ould',\n",
       "    'suffix_3': 'uld',\n",
       "    'suffix_2': 'ld',\n",
       "    'prefix_1': 'w',\n",
       "    'prefix_2': 'wo',\n",
       "    'prefix_3': 'wou',\n",
       "    'prefix_4': 'woul',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'would',\n",
       "    'next_word': 'very',\n",
       "    'word.lower()': 'be',\n",
       "    'suffix_4': 'be',\n",
       "    'suffix_3': 'be',\n",
       "    'suffix_2': 'be',\n",
       "    'prefix_1': 'b',\n",
       "    'prefix_2': 'be',\n",
       "    'prefix_3': 'be',\n",
       "    'prefix_4': 'be',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'be',\n",
       "    'next_word': 'surprised',\n",
       "    'word.lower()': 'very',\n",
       "    'suffix_4': 'very',\n",
       "    'suffix_3': 'ery',\n",
       "    'suffix_2': 'ry',\n",
       "    'prefix_1': 'v',\n",
       "    'prefix_2': 've',\n",
       "    'prefix_3': 'ver',\n",
       "    'prefix_4': 'very',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'very',\n",
       "    'next_word': 'if',\n",
       "    'word.lower()': 'surprised',\n",
       "    'suffix_4': 'ised',\n",
       "    'suffix_3': 'sed',\n",
       "    'suffix_2': 'ed',\n",
       "    'prefix_1': 's',\n",
       "    'prefix_2': 'su',\n",
       "    'prefix_3': 'sur',\n",
       "    'prefix_4': 'surp',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'surprised',\n",
       "    'next_word': 'his',\n",
       "    'word.lower()': 'if',\n",
       "    'suffix_4': 'if',\n",
       "    'suffix_3': 'if',\n",
       "    'suffix_2': 'if',\n",
       "    'prefix_1': 'i',\n",
       "    'prefix_2': 'if',\n",
       "    'prefix_3': 'if',\n",
       "    'prefix_4': 'if',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'if',\n",
       "    'next_word': 'departure',\n",
       "    'word.lower()': 'his',\n",
       "    'suffix_4': 'his',\n",
       "    'suffix_3': 'his',\n",
       "    'suffix_2': 'is',\n",
       "    'prefix_1': 'h',\n",
       "    'prefix_2': 'hi',\n",
       "    'prefix_3': 'his',\n",
       "    'prefix_4': 'his',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'his',\n",
       "    'next_word': 'signals',\n",
       "    'word.lower()': 'departure',\n",
       "    'suffix_4': 'ture',\n",
       "    'suffix_3': 'ure',\n",
       "    'suffix_2': 're',\n",
       "    'prefix_1': 'd',\n",
       "    'prefix_2': 'de',\n",
       "    'prefix_3': 'dep',\n",
       "    'prefix_4': 'depa',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'departure',\n",
       "    'next_word': 'any',\n",
       "    'word.lower()': 'signals',\n",
       "    'suffix_4': 'nals',\n",
       "    'suffix_3': 'als',\n",
       "    'suffix_2': 'ls',\n",
       "    'prefix_1': 's',\n",
       "    'prefix_2': 'si',\n",
       "    'prefix_3': 'sig',\n",
       "    'prefix_4': 'sign',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'signals',\n",
       "    'next_word': 'change',\n",
       "    'word.lower()': 'any',\n",
       "    'suffix_4': 'any',\n",
       "    'suffix_3': 'any',\n",
       "    'suffix_2': 'ny',\n",
       "    'prefix_1': 'a',\n",
       "    'prefix_2': 'an',\n",
       "    'prefix_3': 'any',\n",
       "    'prefix_4': 'any',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'any',\n",
       "    'next_word': 'in',\n",
       "    'word.lower()': 'change',\n",
       "    'suffix_4': 'ange',\n",
       "    'suffix_3': 'nge',\n",
       "    'suffix_2': 'ge',\n",
       "    'prefix_1': 'c',\n",
       "    'prefix_2': 'ch',\n",
       "    'prefix_3': 'cha',\n",
       "    'prefix_4': 'chan',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'change',\n",
       "    'next_word': 'strategy',\n",
       "    'word.lower()': 'in',\n",
       "    'suffix_4': 'in',\n",
       "    'suffix_3': 'in',\n",
       "    'suffix_2': 'in',\n",
       "    'prefix_1': 'i',\n",
       "    'prefix_2': 'in',\n",
       "    'prefix_3': 'in',\n",
       "    'prefix_4': 'in',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'in',\n",
       "    'next_word': 'or',\n",
       "    'word.lower()': 'strategy',\n",
       "    'suffix_4': 'tegy',\n",
       "    'suffix_3': 'egy',\n",
       "    'suffix_2': 'gy',\n",
       "    'prefix_1': 's',\n",
       "    'prefix_2': 'st',\n",
       "    'prefix_3': 'str',\n",
       "    'prefix_4': 'stra',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'strategy',\n",
       "    'next_word': 'change',\n",
       "    'word.lower()': 'or',\n",
       "    'suffix_4': 'or',\n",
       "    'suffix_3': 'or',\n",
       "    'suffix_2': 'or',\n",
       "    'prefix_1': 'o',\n",
       "    'prefix_2': 'or',\n",
       "    'prefix_3': 'or',\n",
       "    'prefix_4': 'or',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'or',\n",
       "    'next_word': 'in',\n",
       "    'word.lower()': 'change',\n",
       "    'suffix_4': 'ange',\n",
       "    'suffix_3': 'nge',\n",
       "    'suffix_2': 'ge',\n",
       "    'prefix_1': 'c',\n",
       "    'prefix_2': 'ch',\n",
       "    'prefix_3': 'cha',\n",
       "    'prefix_4': 'chan',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'change',\n",
       "    'next_word': 'profit',\n",
       "    'word.lower()': 'in',\n",
       "    'suffix_4': 'in',\n",
       "    'suffix_3': 'in',\n",
       "    'suffix_2': 'in',\n",
       "    'prefix_1': 'i',\n",
       "    'prefix_2': 'in',\n",
       "    'prefix_3': 'in',\n",
       "    'prefix_4': 'in',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'in',\n",
       "    'next_word': 'expectations',\n",
       "    'word.lower()': 'profit',\n",
       "    'suffix_4': 'ofit',\n",
       "    'suffix_3': 'fit',\n",
       "    'suffix_2': 'it',\n",
       "    'prefix_1': 'p',\n",
       "    'prefix_2': 'pr',\n",
       "    'prefix_3': 'pro',\n",
       "    'prefix_4': 'prof',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 0,\n",
       "    'prev_word': 'profit',\n",
       "    'next_word': '.',\n",
       "    'word.lower()': 'expectations',\n",
       "    'suffix_4': 'ions',\n",
       "    'suffix_3': 'ons',\n",
       "    'suffix_2': 'ns',\n",
       "    'prefix_1': 'e',\n",
       "    'prefix_2': 'ex',\n",
       "    'prefix_3': 'exp',\n",
       "    'prefix_4': 'expe',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 0,\n",
       "    'is_complete_capital': 1,\n",
       "    'prev_word': 'expectations',\n",
       "    'next_word': \"''\",\n",
       "    'word.lower()': '.',\n",
       "    'suffix_4': '.',\n",
       "    'suffix_3': '.',\n",
       "    'suffix_2': '.',\n",
       "    'prefix_1': '.',\n",
       "    'prefix_2': '.',\n",
       "    'prefix_3': '.',\n",
       "    'prefix_4': '.',\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0},\n",
       "   {'bias': 1.0,\n",
       "    'BOS': 0,\n",
       "    'EOS': 1,\n",
       "    'is_complete_capital': 1,\n",
       "    'prev_word': '.',\n",
       "    'next_word': '',\n",
       "    'word.lower()': \"''\",\n",
       "    'suffix_4': \"''\",\n",
       "    'suffix_3': \"''\",\n",
       "    'suffix_2': \"''\",\n",
       "    'prefix_1': \"'\",\n",
       "    'prefix_2': \"''\",\n",
       "    'prefix_3': \"''\",\n",
       "    'prefix_4': \"''\",\n",
       "    'word.isupper()': False,\n",
       "    'word.istitle()': False,\n",
       "    'word.isdigit()': False,\n",
       "    'is_alphanumeric': 0,\n",
       "    'word_has_hyphen': 0}]],\n",
       " [['PRP',\n",
       "   'MD',\n",
       "   'VB',\n",
       "   'RB',\n",
       "   'VBN',\n",
       "   'IN',\n",
       "   'PRP$',\n",
       "   'NN',\n",
       "   'VBZ',\n",
       "   'DT',\n",
       "   'NN',\n",
       "   'IN',\n",
       "   'NN',\n",
       "   'CC',\n",
       "   'NN',\n",
       "   'IN',\n",
       "   'NN',\n",
       "   'NNS',\n",
       "   '.',\n",
       "   \"''\"]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_dataset([train_data[0]])\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c1b3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_dataset(train_data)\n",
    "X_test, y_test = get_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b53294a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(algorithm=\"lbfgs\", c1=0.01, c2=0.1, max_iterations=150, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0c1b3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.01, c2=0.1,\n",
       "    max_iterations=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.01, c2=0.1,\n",
       "    max_iterations=150)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.01, c2=0.1,\n",
       "    max_iterations=150)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab749ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PRP      0.997     0.991     0.994       317\n",
      "          MD      1.000     0.995     0.997       182\n",
      "          VB      0.942     0.944     0.943       481\n",
      "          RB      0.930     0.901     0.915       545\n",
      "         VBN      0.912     0.908     0.910       434\n",
      "          IN      0.969     0.988     0.979      1988\n",
      "        PRP$      0.994     0.994     0.994       171\n",
      "          NN      0.945     0.960     0.952      2639\n",
      "         VBZ      0.983     0.926     0.954       432\n",
      "          DT      0.994     0.991     0.993      1607\n",
      "          CC      0.998     0.995     0.997       440\n",
      "         NNS      0.963     0.975     0.969      1160\n",
      "           .      1.000     1.000     1.000       767\n",
      "          ''      1.000     1.000     1.000       148\n",
      "         NNP      0.963     0.983     0.973      1875\n",
      "         VBD      0.948     0.939     0.943       603\n",
      "      -NONE-      1.000     1.000     1.000      1271\n",
      "          TO      1.000     0.998     0.999       402\n",
      "           ,      1.000     1.000     1.000       930\n",
      "         WDT      0.988     0.952     0.969        83\n",
      "          CD      0.994     0.990     0.992       704\n",
      "          JJ      0.915     0.910     0.912      1142\n",
      "           $      1.000     1.000     1.000       138\n",
      "         VBG      0.926     0.917     0.921       288\n",
      "          ``      1.000     1.000     1.000       149\n",
      "         VBP      0.921     0.836     0.876       250\n",
      "         POS      0.993     1.000     0.997       144\n",
      "          WP      1.000     1.000     1.000        44\n",
      "         RBR      0.864     0.679     0.760        28\n",
      "          RP      0.758     0.595     0.667        42\n",
      "         JJR      0.875     0.887     0.881        71\n",
      "       -LRB-      1.000     1.000     1.000        25\n",
      "       -RRB-      1.000     1.000     1.000        25\n",
      "           :      1.000     1.000     1.000        96\n",
      "        NNPS      0.794     0.474     0.593        57\n",
      "         JJS      0.951     0.975     0.963        40\n",
      "         WRB      1.000     0.966     0.982        29\n",
      "          EX      0.857     1.000     0.923        12\n",
      "         WP$      1.000     1.000     1.000         3\n",
      "           #      1.000     1.000     1.000         3\n",
      "         PDT      1.000     0.333     0.500         3\n",
      "          LS      0.000     0.000     0.000         0\n",
      "         RBS      0.833     0.833     0.833         6\n",
      "          UH      0.000     0.000     0.000         1\n",
      "          FW      0.000     0.000     0.000         2\n",
      "\n",
      "   micro avg      0.967     0.967     0.967     19777\n",
      "   macro avg      0.893     0.863     0.873     19777\n",
      "weighted avg      0.967     0.967     0.967     19777\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harsh/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harsh/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harsh/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harsh/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harsh/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harsh/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=crf.classes_, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

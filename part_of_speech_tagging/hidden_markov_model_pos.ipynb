{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21bf4f91",
   "metadata": {},
   "source": [
    "*The following is a very naive implementation of a hidden markov model for Part of Speech tagging*<br/>\n",
    "*Several improvements are possible: word preprocessing, handling OOV words etc.*<br/>\n",
    "*The current state of the art transformers do POS tagging with an accuracy of ~98%*<br/>\n",
    "*I was able to acheive a decent matching (90% on 25% held out test corpus) as well with this statistical model*<br/>\n",
    "*However this was due to the \"universal\" taglist which is not as broad (12 labels) instead of the (46 labels) in the original dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94167c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ac8ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nltk.corpus.treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5889876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sents = list(dataset.tagged_sents(tagset=\"universal\"))\n",
    "# tagged_sents = list(dataset.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc481a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  ('is', 'VERB'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Elsevier', 'NOUN'),\n",
       "  ('N.V.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('Dutch', 'NOUN'),\n",
       "  ('publishing', 'VERB'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NOUN'),\n",
       "  ('Agnew', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('55', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('former', 'ADJ'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Consolidated', 'NOUN'),\n",
       "  ('Gold', 'NOUN'),\n",
       "  ('Fields', 'NOUN'),\n",
       "  ('PLC', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('was', 'VERB'),\n",
       "  ('named', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('this', 'DET'),\n",
       "  ('British', 'ADJ'),\n",
       "  ('industrial', 'ADJ'),\n",
       "  ('conglomerate', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('form', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('once', 'ADV'),\n",
       "  ('used', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('make', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('has', 'VERB'),\n",
       "  ('caused', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('high', 'ADJ'),\n",
       "  ('percentage', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('cancer', 'NOUN'),\n",
       "  ('deaths', 'NOUN'),\n",
       "  ('among', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('exposed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('30', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('fiber', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('is', 'VERB'),\n",
       "  ('unusually', 'ADV'),\n",
       "  ('resilient', 'ADJ'),\n",
       "  ('once', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  ('enters', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('lungs', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('with', 'ADP'),\n",
       "  ('even', 'ADV'),\n",
       "  ('brief', 'ADJ'),\n",
       "  ('exposures', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('causing', 'VERB'),\n",
       "  ('symptoms', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('show', 'VERB'),\n",
       "  ('up', 'PRT'),\n",
       "  ('decades', 'NOUN'),\n",
       "  ('later', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83733cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "442be38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2935 979\n"
     ]
    }
   ],
   "source": [
    "n = len(tagged_sents)\n",
    "train_data = tagged_sents[:int(0.75*n)]\n",
    "test_data = tagged_sents[int(0.75*n):]\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09c60151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100676\n"
     ]
    }
   ],
   "source": [
    "word_label_pair_train = [i for sent in tagged_sents for i in sent]\n",
    "print(len(word_label_pair_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ea29e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 12408, and the number of tags are: 12\n"
     ]
    }
   ],
   "source": [
    "vocab_train = list(set([pair[0] for pair in word_label_pair_train]))\n",
    "tags = list(set([pair[1] for pair in word_label_pair_train]))\n",
    "print(f\"Number of tokens: {len(vocab_train)}, and the number of tags are: {len(tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b961a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VERB', 'ADP', 'PRON', 'X', 'PRT', 'NUM', '.', 'ADJ', 'DET', 'CONJ', 'ADV', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed601485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4018 will\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(vocab_train)}\n",
    "index_to_word = {i: word for i, word in enumerate(vocab_train)}\n",
    "tags_to_index = {tag: i for i, tag in enumerate(tags)}\n",
    "index_to_tags = {i: tag for i, tag in enumerate(tags)}\n",
    "\n",
    "print(word_to_index[\"will\"], index_to_word[word_to_index[\"will\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8836591",
   "metadata": {},
   "source": [
    "**The tags are as follows: <br/>\n",
    "[link](https://www.eecis.udel.edu/~vijay/cis889/ie/pos-set.pdf)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe27fbe4",
   "metadata": {},
   "source": [
    "**Emmission probabilities**: The P(w|t) = C(w, t)/C(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a6816ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tags_count = len(tags)\n",
    "vocab_size = len(vocab_train)\n",
    "emmission_counts = np.ones((tags_count, vocab_size)) # add-one smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91af3f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emmision_count(word, tag, data=word_label_pair_train):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        word: (string),\n",
    "        tag: (string),\n",
    "        data: (list of tuples {(word, tag)})\n",
    "    Returns:\n",
    "        (count_word_as_tag, count_tag): (int, int)\n",
    "    \"\"\"\n",
    "\n",
    "    tag_appearance = [tup for tup in data if tup[1] == tag]\n",
    "    count_tag = len(tag_appearance)\n",
    "    word_as_tag = [tup for tup in tag_appearance if tup[0] == word]\n",
    "    count_word_as_tag = len(word_as_tag)\n",
    "    return count_word_as_tag, count_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_will_as_MD, count_MD = emmision_count(\"will\", \"MD\")\n",
    "# print(f\"Count of word 'will' as tag 'MD' is {count_will_as_MD} and count of tag 'MD' is {count_MD} | percentage: {count_will_as_MD/count_MD * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75538f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB is done\n",
      "ADP is done\n",
      "PRON is done\n",
      "X is done\n",
      "PRT is done\n",
      "NUM is done\n",
      ". is done\n",
      "ADJ is done\n",
      "DET is done\n",
      "CONJ is done\n",
      "ADV is done\n",
      "NOUN is done\n"
     ]
    }
   ],
   "source": [
    "# updating the emmission_counts matrix\n",
    "for i, tag in enumerate(tags):\n",
    "    for j, word in enumerate(vocab_train):\n",
    "        emmission_counts[i, j] += emmision_count(word, tag)[0]\n",
    "    print(f\"{index_to_tags[i]} is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db68293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emmission_counts[tags_to_index[\"MD\"], word_to_index[\"will\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55efef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is new it\n"
     ]
    }
   ],
   "source": [
    "# print(index_to_word[np.argmax(emmission_counts[tags_to_index[\"MD\"]])], \n",
    "#       index_to_word[np.argmax(emmission_counts[tags_to_index[\"DT\"]])],\n",
    "#       index_to_word[np.argmax(emmission_counts[tags_to_index[\"JJ\"]])])\n",
    "\n",
    "print(index_to_word[np.argmax(emmission_counts[tags_to_index[\"VERB\"]])], \n",
    "      index_to_word[np.argmax(emmission_counts[tags_to_index[\"ADJ\"]])],\n",
    "      index_to_word[np.argmax(emmission_counts[tags_to_index[\"PRON\"]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1c94139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to obtain the probabilities \n",
    "count_tags = np.zeros(tags_count)\n",
    "for i, tag in enumerate(tags):\n",
    "    count_tags[i] = emmision_count(\"\", tag)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bd62cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tags = count_tags.reshape(-1, 1)\n",
    "\n",
    "emmission_probs = emmission_counts/count_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d116a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281.0, 0.020716602772043645)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emmission_counts[tags_to_index[\"MD\"], word_to_index[\"will\"]], emmission_probs[tags_to_index[\"MD\"], word_to_index[\"will\"]]\n",
    "emmission_counts[tags_to_index[\"VERB\"], word_to_index[\"will\"]], emmission_probs[tags_to_index[\"VERB\"], word_to_index[\"will\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "794145f8",
   "metadata": {},
   "source": [
    "**Transition probabilities** P(t2|t1) = C(t1, t2)/C(t1): probability of a tag given a previous tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b160e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_proba(tag2, tag1, data=word_label_pair_train):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        tag1: (string),\n",
    "        tag2: (string),\n",
    "    Returns:\n",
    "        percentage: (float) P(t2|t1)*100\n",
    "    \"\"\"\n",
    "    count_tag1 = 0\n",
    "    count_tag1_tag2 = 0\n",
    "    tag_list = [tup[1] for tup in data]\n",
    "    for t1, t2 in zip(tag_list, tag_list[1:]):\n",
    "        if t1 == tag1:\n",
    "            count_tag1 += 1\n",
    "            if t2 == tag2:\n",
    "                count_tag1_tag2 += 1\n",
    "    return count_tag1_tag2/count_tag1 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6ff3ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition probability of VERB to ADV is:  34.46862188584043\n"
     ]
    }
   ],
   "source": [
    "# print(\"Transition probability of VB to MD is: \", get_transition_proba(\"VB\", \"MD\")) # prob of a verb following a modal verb\n",
    "print(\"Transition probability of VERB to ADV is: \", get_transition_proba(\"VERB\", \"ADV\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "099fd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the transition matrix\n",
    "transition_probs = np.zeros((tags_count, tags_count)) # transition_probs[i, j] = P(t_j|t_i)\n",
    "for i in range(len(tags)):\n",
    "    for j in range(len(tags)):\n",
    "        transition_probs[i, j] = get_transition_proba(tags[j], tags[i]) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "846546a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3446862188584043"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transition_probs[tags_to_index[\"MD\"], tags_to_index[\"VB\"]]\n",
    "transition_probs[tags_to_index[\"ADV\"], tags_to_index[\"VERB\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fbf711c",
   "metadata": {},
   "source": [
    "![viterbi](./images/viterbi.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f785a157",
   "metadata": {},
   "source": [
    "**VITERBI ALGORITHM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2814f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_probs = [] # initial_state_probs[i] = prob that a sentence starts with tag i\n",
    "for tag in tags:\n",
    "    initial_state_probs.append(get_transition_proba(tag, \".\")/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41e70c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(initial_state_probs), tags_to_index[\"NOUN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b053afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(sentence):\n",
    "    \"\"\"\n",
    "        Parameters:\n",
    "            sentence: (list of strings)\n",
    "        Returns:\n",
    "            tags: (list of strings)\n",
    "    \"\"\"\n",
    "    viterbi = np.zeros((tags_count, len(sentence)))\n",
    "    backpointer = np.zeros((tags_count, len(sentence)), dtype=int)\n",
    "    for i in range(tags_count):\n",
    "        viterbi[i, 0] = initial_state_probs[i] * emmission_probs[i, word_to_index[sentence[0]]]\n",
    "        backpointer[i, 0] = 0\n",
    "    for t in range(1, len(sentence)):\n",
    "        for s in range(tags_count):\n",
    "            # error if word is not in train vocab\n",
    "            if sentence[t] not in vocab_train:\n",
    "                viterbi[s, t] = np.max(viterbi[:, t-1] * transition_probs[:, s])\n",
    "                backpointer[s, t] = np.argmax(viterbi[:, t-1] * transition_probs[:, s])\n",
    "                continue\n",
    "            viterbi[s, t] = np.max(viterbi[:, t-1] * transition_probs[:, s]) * emmission_probs[s, word_to_index[sentence[t]]]\n",
    "            backpointer[s, t] = np.argmax(viterbi[:, t-1] * transition_probs[:, s])\n",
    "    best_path_prob = np.max(viterbi[:, -1])\n",
    "    best_path_pointer = np.argmax(viterbi[:, -1])\n",
    "    best_path = [best_path_pointer]\n",
    "    for i in range(len(sentence)-1, 0, -1):\n",
    "        best_path_pointer = backpointer[best_path_pointer, i]\n",
    "        best_path.append(best_path_pointer)\n",
    "    best_path.reverse()\n",
    "    return best_path, best_path_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa5459c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence is:  ['The', 'governor', 'could', \"n't\", 'make', 'it', ',', 'so', 'the', 'lieutenant', 'governor', 'welcomed', 'the', 'special', 'guests', '.']\n",
      "act.:['DET', 'NOUN', 'VERB', 'ADV', 'VERB', 'PRON', '.', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'DET', 'ADJ', 'NOUN', '.']\n",
      "pre.:['DET', 'NOUN', 'VERB', 'ADV', 'VERB', 'PRON', '.', 'ADV', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.']\n",
      "The percentage match is: 81.25\n"
     ]
    }
   ],
   "source": [
    "# let us test it on the first train sentence\n",
    "sentence = tagged_sents[78]\n",
    "sentence_words = [tup[0] for tup in sentence]\n",
    "sentence_tags = [tup[1] for tup in sentence]\n",
    "\n",
    "best_path, _ = Viterbi(sentence_words)\n",
    "\n",
    "print(\"The sentence is: \", sentence_words)\n",
    "print(f\"act.:{sentence_tags}\")\n",
    "print(f\"pre.:{[index_to_tags[i] for i in best_path]}\")\n",
    "print(f\"The percentage match is: {sum([1 if i==j else 0 for i, j in zip(sentence_tags, [index_to_tags[i] for i in best_path])])/len(sentence_tags) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc91e531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence is:  ['The', 'reduced', 'dividend', 'is', 'payable', 'Jan.', '2', 'to', 'stock', 'of', 'record', 'Dec.', '15', '.']\n",
      "act.:['DET', 'VERB', 'NOUN', 'VERB', 'ADJ', 'NOUN', 'NUM', 'PRT', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'NUM', '.']\n",
      "pre.:['DET', 'ADJ', 'NOUN', 'VERB', 'X', 'PRT', 'NUM', 'PRT', 'NOUN', 'ADP', 'NOUN', '.', 'NUM', '.']\n",
      "The percentage match is: 71.42857142857143\n",
      "\n",
      "\n",
      "The sentence is:  ['Some', 'Democrats', ',', 'led', '*', 'by', 'Rep.', 'Jack', 'Brooks', '-LRB-', 'D.', ',', 'Texas', '-RRB-', ',', 'unsuccessfully', 'opposed', 'the', 'measure', 'because', 'they', 'fear', 'that', 'the', 'fees', 'may', 'not', 'fully', 'make', 'up', 'for', 'the', 'budget', 'cuts', '.']\n",
      "act.:['ADV', 'NOUN', '.', 'VERB', 'X', 'ADP', 'NOUN', 'NOUN', 'NOUN', '.', 'NOUN', '.', 'NOUN', '.', '.', 'ADV', 'VERB', 'DET', 'NOUN', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'ADV', 'ADV', 'VERB', 'PRT', 'ADP', 'DET', 'NOUN', 'NOUN', '.']\n",
      "pre.:['DET', 'NOUN', '.', 'VERB', 'X', 'ADP', 'NOUN', 'NOUN', 'NOUN', '.', 'NOUN', '.', 'NOUN', '.', '.', 'ADV', 'VERB', 'DET', 'NOUN', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'ADV', 'ADV', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', 'NOUN', '.']\n",
      "The percentage match is: 94.28571428571428\n",
      "\n",
      "\n",
      "The sentence is:  ['The', 'offer', ',', 'which', '*T*-2', 'follows', 'a', '$', '55-a-share', '*U*', 'bid', 'that', '*T*-3', 'was', 'rejected', '*-1', 'in', 'September', ',', 'steps', 'up', 'pressure', 'on', 'the', 'chemicals', 'concern', '.']\n",
      "act.:['DET', 'NOUN', '.', 'DET', 'X', 'VERB', 'DET', '.', 'ADJ', 'X', 'NOUN', 'DET', 'X', 'VERB', 'VERB', 'X', 'ADP', 'NOUN', '.', 'VERB', 'PRT', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', '.']\n",
      "pre.:['DET', 'NOUN', '.', 'DET', 'X', 'VERB', 'DET', '.', 'NUM', 'X', 'NOUN', 'ADP', 'X', 'VERB', 'VERB', 'X', 'ADP', 'NOUN', '.', 'NOUN', 'PRT', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', '.']\n",
      "The percentage match is: 88.88888888888889\n",
      "\n",
      "\n",
      "The sentence is:  ['INTER-TEL', 'Inc', '.', '-LRB-', 'Chandler', ',', 'Ariz.', '-RRB-', '--']\n",
      "act.:['NOUN', 'NOUN', '.', '.', 'NOUN', '.', 'NOUN', '.', '.']\n",
      "pre.:['DET', 'NOUN', '.', '.', 'NOUN', '.', 'NOUN', '.', '.']\n",
      "The percentage match is: 88.88888888888889\n",
      "\n",
      "\n",
      "The sentence is:  ['The', 'McAlpine', 'family', ',', 'which', '*T*-1', 'operates', 'a', 'number', 'of', 'multinational', 'companies', ',', 'including', 'a', 'London-based', 'engineering', 'and', 'construction', 'company', ',', 'also', 'lent', 'to', 'Meridian', 'National', '$', '500,000', '*U*', '.']\n",
      "act.:['DET', 'NOUN', 'NOUN', '.', 'DET', 'X', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.', 'VERB', 'DET', 'ADJ', 'NOUN', 'CONJ', 'NOUN', 'NOUN', '.', 'ADV', 'VERB', 'PRT', 'NOUN', 'NOUN', '.', 'NUM', 'X', '.']\n",
      "pre.:['DET', 'NOUN', 'NOUN', '.', 'DET', 'X', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', '.', 'VERB', 'DET', 'ADJ', 'NOUN', 'CONJ', 'NOUN', 'NOUN', '.', 'ADV', 'VERB', 'PRT', 'NOUN', 'NOUN', '.', 'NUM', 'X', '.']\n",
      "The percentage match is: 96.66666666666667\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing \n",
    "import random\n",
    "rnd = [random.randint(0, len(tagged_sents)) for i in range(5)]\n",
    "for i in rnd:\n",
    "    sentence = tagged_sents[i]\n",
    "    sentence_words = [tup[0] for tup in sentence]\n",
    "    sentence_tags = [tup[1] for tup in sentence]\n",
    "    best_path, _ = Viterbi(sentence_words)\n",
    "    print(\"The sentence is: \", sentence_words)\n",
    "    print(f\"act.:{sentence_tags}\")\n",
    "    print(f\"pre.:{[index_to_tags[i] for i in best_path]}\")\n",
    "    print(f\"The percentage match is: {sum([1 if i==j else 0 for i, j in zip(sentence_tags, [index_to_tags[i] for i in best_path])])/len(sentence_tags) * 100}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36a6cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 90.97300337457817\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "for sent in test_data:\n",
    "  sent_words = [pair[0] for pair in sent]\n",
    "  sent_tags = [pair[1] for pair in sent]  \n",
    "  best_path, _ = Viterbi(sent_words)\n",
    "  correct += sum([1 if i==j else 0 for i, j in zip(sent_tags, [index_to_tags[k] for k in best_path])])\n",
    "  total += len(sent_tags)\n",
    "\n",
    "print(f\"Test accuracy: {(correct/total)*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

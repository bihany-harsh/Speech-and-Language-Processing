{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21bf4f91",
   "metadata": {},
   "source": [
    "*The following is a very naive implementation of a hidden markov model for Part of Speech tagging*<br/>\n",
    "*Several improvements are possible: word preprocessing, handling OOV words etc.*<br/>\n",
    "*The current state of the art transformers do POS tagging with an accuracy of ~98%*<br/>\n",
    "*I was able to acheive 70% matching (approx.) with this statistical model*<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94167c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ac8ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nltk.corpus.treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5889876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sents = list(dataset.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc481a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NNP'),\n",
       "  ('Vinken', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('61', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('old', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('will', 'MD'),\n",
       "  ('join', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('board', 'NN'),\n",
       "  ('as', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('nonexecutive', 'JJ'),\n",
       "  ('director', 'NN'),\n",
       "  ('Nov.', 'NNP'),\n",
       "  ('29', 'CD'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NNP'),\n",
       "  ('Vinken', 'NNP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('chairman', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Elsevier', 'NNP'),\n",
       "  ('N.V.', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('Dutch', 'NNP'),\n",
       "  ('publishing', 'VBG'),\n",
       "  ('group', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NNP'),\n",
       "  ('Agnew', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('55', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('old', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('former', 'JJ'),\n",
       "  ('chairman', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Consolidated', 'NNP'),\n",
       "  ('Gold', 'NNP'),\n",
       "  ('Fields', 'NNP'),\n",
       "  ('PLC', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('was', 'VBD'),\n",
       "  ('named', 'VBN'),\n",
       "  ('*-1', '-NONE-'),\n",
       "  ('a', 'DT'),\n",
       "  ('nonexecutive', 'JJ'),\n",
       "  ('director', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('this', 'DT'),\n",
       "  ('British', 'JJ'),\n",
       "  ('industrial', 'JJ'),\n",
       "  ('conglomerate', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DT'),\n",
       "  ('form', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('asbestos', 'NN'),\n",
       "  ('once', 'RB'),\n",
       "  ('used', 'VBN'),\n",
       "  ('*', '-NONE-'),\n",
       "  ('*', '-NONE-'),\n",
       "  ('to', 'TO'),\n",
       "  ('make', 'VB'),\n",
       "  ('Kent', 'NNP'),\n",
       "  ('cigarette', 'NN'),\n",
       "  ('filters', 'NNS'),\n",
       "  ('has', 'VBZ'),\n",
       "  ('caused', 'VBN'),\n",
       "  ('a', 'DT'),\n",
       "  ('high', 'JJ'),\n",
       "  ('percentage', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('cancer', 'NN'),\n",
       "  ('deaths', 'NNS'),\n",
       "  ('among', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('group', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('workers', 'NNS'),\n",
       "  ('exposed', 'VBN'),\n",
       "  ('*', '-NONE-'),\n",
       "  ('to', 'TO'),\n",
       "  ('it', 'PRP'),\n",
       "  ('more', 'RBR'),\n",
       "  ('than', 'IN'),\n",
       "  ('30', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('ago', 'IN'),\n",
       "  (',', ','),\n",
       "  ('researchers', 'NNS'),\n",
       "  ('reported', 'VBD'),\n",
       "  ('0', '-NONE-'),\n",
       "  ('*T*-1', '-NONE-'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DT'),\n",
       "  ('asbestos', 'NN'),\n",
       "  ('fiber', 'NN'),\n",
       "  (',', ','),\n",
       "  ('crocidolite', 'NN'),\n",
       "  (',', ','),\n",
       "  ('is', 'VBZ'),\n",
       "  ('unusually', 'RB'),\n",
       "  ('resilient', 'JJ'),\n",
       "  ('once', 'IN'),\n",
       "  ('it', 'PRP'),\n",
       "  ('enters', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('lungs', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('with', 'IN'),\n",
       "  ('even', 'RB'),\n",
       "  ('brief', 'JJ'),\n",
       "  ('exposures', 'NNS'),\n",
       "  ('to', 'TO'),\n",
       "  ('it', 'PRP'),\n",
       "  ('causing', 'VBG'),\n",
       "  ('symptoms', 'NNS'),\n",
       "  ('that', 'WDT'),\n",
       "  ('*T*-1', '-NONE-'),\n",
       "  ('show', 'VBP'),\n",
       "  ('up', 'RP'),\n",
       "  ('decades', 'NNS'),\n",
       "  ('later', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('researchers', 'NNS'),\n",
       "  ('said', 'VBD'),\n",
       "  ('0', '-NONE-'),\n",
       "  ('*T*-2', '-NONE-'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83733cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "442be38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2935 979\n"
     ]
    }
   ],
   "source": [
    "n = len(tagged_sents)\n",
    "train_data = tagged_sents[:int(0.75*n)]\n",
    "test_data = tagged_sents[int(0.75*n):]\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c60151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75784\n"
     ]
    }
   ],
   "source": [
    "word_label_pair_train = [i for sent in train_data for i in sent]\n",
    "print(len(word_label_pair_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea29e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 10634, and the number of tags are: 46\n"
     ]
    }
   ],
   "source": [
    "vocab_train = list(set([pair[0] for pair in word_label_pair_train]))\n",
    "tags = list(set([pair[1] for pair in word_label_pair_train]))\n",
    "print(f\"Number of tokens: {len(vocab_train)}, and the number of tags are: {len(tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b961a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VBP', '-LRB-', 'JJ', '#', 'SYM', ',', '``', 'DT', 'WP$', '$', 'POS', 'UH', 'RB', 'NN', 'MD', \"''\", 'VB', 'CC', 'VBN', 'NNP', 'JJR', 'PRP', '-NONE-', 'PDT', 'TO', '.', 'WDT', 'RBS', 'IN', 'JJS', ':', 'CD', 'RP', 'RBR', '-RRB-', 'EX', 'NNPS', 'VBD', 'FW', 'VBG', 'NNS', 'VBZ', 'WP', 'WRB', 'LS', 'PRP$']\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed601485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847 will\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(vocab_train)}\n",
    "index_to_word = {i: word for i, word in enumerate(vocab_train)}\n",
    "tags_to_index = {tag: i for i, tag in enumerate(tags)}\n",
    "index_to_tags = {i: tag for i, tag in enumerate(tags)}\n",
    "\n",
    "print(word_to_index[\"will\"], index_to_word[word_to_index[\"will\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8836591",
   "metadata": {},
   "source": [
    "**The tags are as follows: <br/>\n",
    "[link](https://www.eecis.udel.edu/~vijay/cis889/ie/pos-set.pdf)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe27fbe4",
   "metadata": {},
   "source": [
    "**Emmission probabilities**: The P(w|t) = C(w, t)/C(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a6816ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tags_count = len(tags)\n",
    "vocab_size = len(vocab_train)\n",
    "emmission_counts = np.ones((tags_count, vocab_size)) # add-one smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91af3f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emmision_count(word, tag, data=word_label_pair_train):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        word: (string),\n",
    "        tag: (string),\n",
    "        data: (list of tuples {(word, tag)})\n",
    "    Returns:\n",
    "        (count_word_as_tag, count_tag): (int, int)\n",
    "    \"\"\"\n",
    "\n",
    "    tag_appearance = [tup for tup in data if tup[1] == tag]\n",
    "    count_tag = len(tag_appearance)\n",
    "    word_as_tag = [tup for tup in tag_appearance if tup[0] == word]\n",
    "    count_word_as_tag = len(word_as_tag)\n",
    "    return count_word_as_tag, count_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "979f768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of word 'will' as tag 'MD' is 202 and count of tag 'MD' is 681 | percentage: 29.662261380323052\n"
     ]
    }
   ],
   "source": [
    "count_will_as_MD, count_MD = emmision_count(\"will\", \"MD\")\n",
    "print(f\"Count of word 'will' as tag 'MD' is {count_will_as_MD} and count of tag 'MD' is {count_MD} | percentage: {count_will_as_MD/count_MD * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "75538f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBP is done\n",
      "-LRB- is done\n",
      "JJ is done\n",
      "# is done\n",
      "SYM is done\n",
      ", is done\n",
      "`` is done\n",
      "DT is done\n",
      "WP$ is done\n",
      "$ is done\n",
      "POS is done\n",
      "UH is done\n",
      "RB is done\n",
      "NN is done\n",
      "MD is done\n",
      "'' is done\n",
      "VB is done\n",
      "CC is done\n",
      "VBN is done\n",
      "NNP is done\n",
      "JJR is done\n",
      "PRP is done\n",
      "-NONE- is done\n",
      "PDT is done\n",
      "TO is done\n",
      ". is done\n",
      "WDT is done\n",
      "RBS is done\n",
      "IN is done\n",
      "JJS is done\n",
      ": is done\n",
      "CD is done\n",
      "RP is done\n",
      "RBR is done\n",
      "-RRB- is done\n",
      "EX is done\n",
      "NNPS is done\n",
      "VBD is done\n",
      "FW is done\n",
      "VBG is done\n",
      "NNS is done\n",
      "VBZ is done\n",
      "WP is done\n",
      "WRB is done\n",
      "LS is done\n",
      "PRP$ is done\n"
     ]
    }
   ],
   "source": [
    "# updating the emmission_counts matrix\n",
    "for i, tag in enumerate(tags):\n",
    "    for j, word in enumerate(vocab_train):\n",
    "        emmission_counts[i, j] += emmision_count(word, tag)[0]\n",
    "    print(f\"{index_to_tags[i]} is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db68293e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emmission_counts[tags_to_index[\"MD\"], word_to_index[\"will\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "55efef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will the new\n"
     ]
    }
   ],
   "source": [
    "print(index_to_word[np.argmax(emmission_counts[tags_to_index[\"MD\"]])], \n",
    "      index_to_word[np.argmax(emmission_counts[tags_to_index[\"DT\"]])],\n",
    "      index_to_word[np.argmax(emmission_counts[tags_to_index[\"JJ\"]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b1c94139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to obtain the probabilities \n",
    "count_tags = np.zeros(tags_count)\n",
    "for i, tag in enumerate(tags):\n",
    "    count_tags[i] = emmision_count(\"\", tag)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0bd62cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tags = count_tags.reshape(-1, 1)\n",
    "\n",
    "emmission_probs = emmission_counts/count_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5d116a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203.0, 0.29809104258443464)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emmission_counts[tags_to_index[\"MD\"], word_to_index[\"will\"]], emmission_probs[tags_to_index[\"MD\"], word_to_index[\"will\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "794145f8",
   "metadata": {},
   "source": [
    "**Transition probabilities** P(t2|t1) = C(t1, t2)/C(t1): probability of a tag given a previous tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b160e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_proba(tag2, tag1, data=word_label_pair_train):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        tag1: (string),\n",
    "        tag2: (string),\n",
    "    Returns:\n",
    "        percentage: (float) P(t2|t1)*100\n",
    "    \"\"\"\n",
    "    count_tag1 = 0\n",
    "    count_tag1_tag2 = 0\n",
    "    tag_list = [tup[1] for tup in data]\n",
    "    for t1, t2 in zip(tag_list, tag_list[1:]):\n",
    "        if t1 == tag1:\n",
    "            count_tag1 += 1\n",
    "            if t2 == tag2:\n",
    "                count_tag1_tag2 += 1\n",
    "    return count_tag1_tag2/count_tag1 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6ff3ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition probability of VB to MD is:  80.76358296622614\n"
     ]
    }
   ],
   "source": [
    "print(\"Transition probability of VB to MD is: \", get_transition_proba(\"VB\", \"MD\")) # prob of a verb following a modal verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "099fd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the transition matrix\n",
    "transition_probs = np.zeros((tags_count, tags_count)) # transition_probs[i, j] = P(t_j|t_i)\n",
    "for i in range(len(tags)):\n",
    "    for j in range(len(tags)):\n",
    "        transition_probs[i, j] = get_transition_proba(tags[j], tags[i]) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "846546a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076358296622614"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_probs[tags_to_index[\"MD\"], tags_to_index[\"VB\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fbf711c",
   "metadata": {},
   "source": [
    "![viterbi](./images/viterbi.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f785a157",
   "metadata": {},
   "source": [
    "**VITERBI ALGORITHM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2814f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_probs = [] # initial_state_probs[i] = prob that a sentence starts with tag i\n",
    "for tag in tags:\n",
    "    initial_state_probs.append(get_transition_proba(tag, \".\")/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41e70c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(initial_state_probs), tags_to_index[\"DT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b053afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(sentence):\n",
    "    \"\"\"\n",
    "        Parameters:\n",
    "            sentence: (list of strings)\n",
    "        Returns:\n",
    "            tags: (list of strings)\n",
    "    \"\"\"\n",
    "    viterbi = np.zeros((tags_count, len(sentence)))\n",
    "    backpointer = np.zeros((tags_count, len(sentence)), dtype=int)\n",
    "    for i in range(tags_count):\n",
    "        viterbi[i, 0] = initial_state_probs[i] * emmission_probs[i, word_to_index[sentence[0]]]\n",
    "        backpointer[i, 0] = 0\n",
    "    for t in range(1, len(sentence)):\n",
    "        for s in range(tags_count):\n",
    "            # error if word is not in train vocab\n",
    "            if sentence[t] not in vocab_train:\n",
    "                viterbi[s, t] = np.max(viterbi[:, t-1] * transition_probs[:, s])\n",
    "                backpointer[s, t] = np.argmax(viterbi[:, t-1] * transition_probs[:, s])\n",
    "                continue\n",
    "            viterbi[s, t] = np.max(viterbi[:, t-1] * transition_probs[:, s]) * emmission_probs[s, word_to_index[sentence[t]]]\n",
    "            backpointer[s, t] = np.argmax(viterbi[:, t-1] * transition_probs[:, s])\n",
    "    best_path_prob = np.max(viterbi[:, -1])\n",
    "    best_path_pointer = np.argmax(viterbi[:, -1])\n",
    "    best_path = [best_path_pointer]\n",
    "    for i in range(len(sentence)-1, 0, -1):\n",
    "        best_path_pointer = backpointer[best_path_pointer, i]\n",
    "        best_path.append(best_path_pointer)\n",
    "    best_path.reverse()\n",
    "    return best_path, best_path_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "aa5459c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence is:  ['The', 'governor', 'could', \"n't\", 'make', 'it', ',', 'so', 'the', 'lieutenant', 'governor', 'welcomed', 'the', 'special', 'guests', '.']\n",
      "act.:['DT', 'NN', 'MD', 'RB', 'VB', 'PRP', ',', 'IN', 'DT', 'NN', 'NN', 'VBD', 'DT', 'JJ', 'NNS', '.']\n",
      "pre.:['DT', 'NN', 'MD', 'RB', 'VB', 'PRP', ',', 'RB', 'DT', 'FW', '-RRB-', ':', 'DT', 'JJ', 'NNS', '.']\n",
      "The percentage match is: 75.0\n"
     ]
    }
   ],
   "source": [
    "# let us test it on the first train sentence\n",
    "sentence = tagged_sents[78]\n",
    "sentence_words = [tup[0] for tup in sentence]\n",
    "sentence_tags = [tup[1] for tup in sentence]\n",
    "\n",
    "best_path, _ = Viterbi(sentence_words)\n",
    "\n",
    "print(\"The sentence is: \", sentence_words)\n",
    "print(f\"act.:{sentence_tags}\")\n",
    "print(f\"pre.:{[index_to_tags[i] for i in best_path]}\")\n",
    "print(f\"The percentage match is: {sum([1 if i==j else 0 for i, j in zip(sentence_tags, [index_to_tags[i] for i in best_path])])/len(sentence_tags) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cc91e531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence is:  ['Commonwealth', 'Edison', 'now', 'faces', 'an', 'additional', 'court-ordered', 'refund', 'on', 'its', 'summer\\\\/winter', 'rate', 'differential', 'collections', 'that', 'the', 'Illinois', 'Appellate', 'Court', 'has', 'estimated', '*T*-1', 'at', '$', '140', 'million', '*U*', '.']\n",
      "act.:['NNP', 'NNP', 'RB', 'VBZ', 'DT', 'JJ', 'JJ', 'NN', 'IN', 'PRP$', 'JJ', 'NN', 'JJ', 'NNS', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'VBZ', 'VBN', '-NONE-', 'IN', '$', 'CD', 'CD', '-NONE-', '.']\n",
      "pre.:['LS', '-RRB-', ':', 'LS', '-RRB-', ':', 'LS', '-RRB-', ':', 'LS', '-RRB-', ':', 'LS', '-RRB-', 'IN', 'DT', 'NNP', 'SYM', 'NNP', 'VBZ', 'VBN', '-NONE-', 'IN', '$', 'CD', 'CD', '-NONE-', '.']\n",
      "The percentage match is: 46.42857142857143\n",
      "\n",
      "\n",
      "The sentence is:  ['Analysts', 'were', 'disappointed', '*-112', 'that', 'the', 'enthusiasm', '*ICH*-2', '0', 'investors', 'showed', '*T*-1', 'for', 'stocks', 'in', 'the', 'wake', 'of', 'Georgia-Pacific', \"'s\", '$', '3.18', 'billion', '*U*', 'bid', 'for', 'Great', 'Northern', 'Nekoosa', 'evaporated', 'so', 'quickly', '.']\n",
      "act.:['NNS', 'VBD', 'VBN', '-NONE-', 'IN', 'DT', 'NN', '-NONE-', '-NONE-', 'NNS', 'VBD', '-NONE-', 'IN', 'NNS', 'IN', 'DT', 'NN', 'IN', 'NNP', 'POS', '$', 'CD', 'CD', '-NONE-', 'NN', 'IN', 'JJ', 'NNP', 'NNP', 'VBD', 'RB', 'RB', '.']\n",
      "pre.:['LS', ':', 'LS', '-RRB-', 'IN', 'DT', 'FW', '-RRB-', '-NONE-', 'PRP', 'VBD', '-NONE-', 'IN', 'NNS', 'IN', 'DT', 'NN', 'IN', 'NNP', 'POS', '$', 'CD', 'CD', '-NONE-', ':', 'LS', '-RRB-', ':', 'LS', '-RRB-', ':', 'LS', '.']\n",
      "The percentage match is: 54.54545454545454\n",
      "\n",
      "\n",
      "The sentence is:  ['``', 'These', 'two', 'exposures', 'alone', 'represent', 'a', 'very', 'substantial', 'portion', 'of', 'CS', 'First', 'Boston', \"'s\", 'equity', ',', \"''\", 'Moody', \"'s\", 'said', '*T*-1', '.']\n",
      "act.:['``', 'DT', 'CD', 'NNS', 'RB', 'VBP', 'DT', 'RB', 'JJ', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'POS', 'NN', ',', \"''\", 'NNP', 'POS', 'VBD', '-NONE-', '.']\n",
      "pre.:['``', 'DT', 'FW', '-RRB-', ':', 'LS', '-RRB-', ':', 'LS', '-RRB-', 'IN', 'NNP', 'NNP', 'NNP', 'POS', 'NN', ',', \"''\", 'NNP', 'POS', 'VBD', '-NONE-', '.']\n",
      "The percentage match is: 65.21739130434783\n",
      "\n",
      "\n",
      "The sentence is:  ['But', 'company', 'officials', 'said', 'yesterday', 'that', 'they', 'decided', '*-2', 'to', 'take', 'a', '$', '43', 'million', '*U*', 'pretax', 'charge', 'for', 'the', 'period', '*-3', 'to', 'cover', 'a', 'restructuring', 'of', 'world-wide', 'manufacturing', 'operations', ',', '*-4', 'citing', 'extended', 'weakness', 'in', 'the', 'market', 'as', 'well', 'as', 'a', 'decision', '*', 'to', 'switch', 'to', 'more', 'economical', 'production', 'techniques', '.']\n",
      "act.:['CC', 'NN', 'NNS', 'VBD', 'NN', 'IN', 'PRP', 'VBD', '-NONE-', 'TO', 'VB', 'DT', '$', 'CD', 'CD', '-NONE-', 'JJ', 'NN', 'IN', 'DT', 'NN', '-NONE-', 'TO', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NN', 'NNS', ',', '-NONE-', 'VBG', 'JJ', 'NN', 'IN', 'DT', 'NN', 'RB', 'RB', 'IN', 'DT', 'NN', '-NONE-', 'TO', 'VB', 'TO', 'JJR', 'JJ', 'NN', 'NNS', '.']\n",
      "pre.:['CC', 'NN', 'NNS', 'VBD', 'UH', 'IN', 'PRP', 'VBD', '-NONE-', 'TO', 'VB', 'DT', '$', 'CD', 'CD', '-NONE-', 'TO', 'VB', 'IN', 'DT', 'NN', '-NONE-', 'TO', 'VB', 'DT', 'NN', 'IN', 'FW', '-RRB-', ':', 'LS', '-RRB-', ':', 'LS', '-RRB-', 'IN', 'DT', 'NN', 'IN', 'RB', 'IN', 'DT', 'NN', '-NONE-', 'TO', 'VB', 'TO', 'RBR', ':', 'LS', '-RRB-', '.']\n",
      "The percentage match is: 69.23076923076923\n",
      "\n",
      "\n",
      "The sentence is:  ['``', 'Feeding', 'Frenzy', \"''\", 'does', 'provide', 'a', 'few', 'clues', '.']\n",
      "act.:['``', 'NNP', 'NNP', \"''\", 'VBZ', 'VB', 'DT', 'JJ', 'NNS', '.']\n",
      "pre.:['``', 'NN', '.', \"''\", 'VBZ', 'PDT', 'DT', 'JJ', 'NNS', '.']\n",
      "The percentage match is: 70.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing \n",
    "import random\n",
    "rnd = [random.randint(0, len(tagged_sents)) for i in range(5)]\n",
    "for i in rnd:\n",
    "    sentence = tagged_sents[i]\n",
    "    sentence_words = [tup[0] for tup in sentence]\n",
    "    sentence_tags = [tup[1] for tup in sentence]\n",
    "    best_path, _ = Viterbi(sentence_words)\n",
    "    print(\"The sentence is: \", sentence_words)\n",
    "    print(f\"act.:{sentence_tags}\")\n",
    "    print(f\"pre.:{[index_to_tags[i] for i in best_path]}\")\n",
    "    print(f\"The percentage match is: {sum([1 if i==j else 0 for i, j in zip(sentence_tags, [index_to_tags[i] for i in best_path])])/len(sentence_tags) * 100}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

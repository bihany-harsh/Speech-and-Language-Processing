{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlUEqWGix3Vq",
        "outputId": "4443a1a6-0319-41d3-c95c-cf311f360830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: Morfessor\n",
            "Successfully installed Morfessor-2.0.6\n",
            "Mounted at /content/drive/\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "!pip install Morfessor\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "rdjoA8FczZpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INDIC_NLP_LIB_HOME = \"/content/drive/MyDrive/neural_machine_translation/nmt_iitk/indic_nlp_library\"\n",
        "INDIC_NLP_RESOURCES = \"/content/drive/MyDrive/neural_machine_translation/nmt_iitk/indic_nlp_resources\"\n",
        "import sys\n",
        "sys.path.append(r\"{}\".format(INDIC_NLP_LIB_HOME))\n",
        "from indicnlp import common, loader\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
        "loader.load()\n",
        "\n",
        "sys.path.append(\"/content/drive/MyDrive/neural_machine_translation/iter5/code\")\n",
        "from data_preprocessing import retrieve_sents\n",
        "en_be_src, en_be_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/train_data1.json\", \"English-Bengali\")\n",
        "en_hi_src, en_hi_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/train_data1.json\", \"English-Hindi\")\n",
        "en_gu_src, en_gu_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/train_data1.json\", \"English-Gujarati\")\n",
        "en_ka_src, en_ka_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/train_data1.json\", \"English-Kannada\")\n",
        "en_ma_src, en_ma_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/train_data1.json\", \"English-Malayalam\")\n",
        "en_ta_src, en_ta_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/train_data1.json\", \"English-Tamil\")\n",
        "en_te_src, en_te_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/train_data1.json\", \"English-Telgu\")\n",
        "from data_preprocessing import english_preprocess\n",
        "en_be_src = [english_preprocess(sent) for sent in en_be_src]\n",
        "en_hi_src = [english_preprocess(sent) for sent in en_hi_src]\n",
        "en_ka_src = [english_preprocess(sent) for sent in en_ka_src]\n",
        "en_ma_src = [english_preprocess(sent) for sent in en_ma_src]\n",
        "en_gu_src = [english_preprocess(sent) for sent in en_gu_src]\n",
        "en_ta_src = [english_preprocess(sent) for sent in en_ta_src]\n",
        "en_te_src = [english_preprocess(sent) for sent in en_te_src]\n",
        "\n",
        "from language import Language, make_language\n",
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/neural_machine_translation/iter5/saves/language_instances/en_lang.pkl\", \"rb\") as f:\n",
        "    en_lang = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/neural_machine_translation/iter5/saves/language_instances/hi_lang.pkl\", \"rb\") as f:\n",
        "    hi_lang = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/neural_machine_translation/iter5/saves/language_instances/be_lang.pkl\", \"rb\") as f:\n",
        "    be_lang = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/neural_machine_translation/iter5/saves/language_instances/gu_lang.pkl\", \"rb\") as f:\n",
        "    gu_lang = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/neural_machine_translation/iter5/saves/language_instances/ta_lang.pkl\", \"rb\") as f:\n",
        "    ta_lang = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/neural_machine_translation/iter5/saves/language_instances/ka_lang.pkl\", \"rb\") as f:\n",
        "    ka_lang = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/neural_machine_translation/iter5/saves/language_instances/te_lang.pkl\", \"rb\") as f:\n",
        "    te_lang = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/neural_machine_translation/iter5/saves/language_instances/ma_lang.pkl\", \"rb\") as f:\n",
        "    ma_lang = pickle.load(f)"
      ],
      "metadata": {
        "id": "5imhEPFryQuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 40"
      ],
      "metadata": {
        "id": "9-7CT2n8y1JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class EncoderRNN(nn.Module):\n",
        "#     def __init__(self, input_size, embed_size, hidden_size, dropout_p=0.1):\n",
        "#         super(EncoderRNN, self).__init__()\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.embedding = nn.Embedding(input_size, embed_size)\n",
        "#         self.gru = nn.GRU(embed_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "#         self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         # input: (batch_size, seq_len)\n",
        "#         embedded = self.dropout(self.embedding(input))\n",
        "#         output, hidden = self.gru(embedded)\n",
        "#         # hidden = hidden[0:1] + hidden[1:2]\n",
        "#         hidden = torch.cat((hidden[0:1], hidden[1:2]), dim=2)\n",
        "#         return output, hidden\n",
        "\n",
        "# # based on Bahdanau et al. 2015\n",
        "# class Attention(nn.Module):\n",
        "#     def __init__(self, hidden_size):\n",
        "#         super(Attention, self).__init__()\n",
        "#         self.W = nn.Linear(hidden_size, 2 * hidden_size)\n",
        "#         self.U = nn.Linear(2 * hidden_size, 2 * hidden_size)\n",
        "#         self.V = nn.Linear(2 * hidden_size, 1)\n",
        "\n",
        "#     def forward(self, query, keys):\n",
        "#         # query: [batch_size, 1, hidden_size]\n",
        "#         # keys: [batch_size, seq_len, hidden_size]\n",
        "\n",
        "#         scores = self.V(torch.tanh(self.W(query) + self.U(keys))) # scores: [batch_size, seq_len, 1]\n",
        "#         scores = scores.squeeze(2).unsqueeze(1) # scores: [batch_size, 1, seq_len]\n",
        "#         weights = F.softmax(scores, dim=-1)\n",
        "#         context = torch.bmm(weights, keys) # batch matrix multiplication\n",
        "#         return context, weights\n",
        "\n",
        "# class AttentionDecoderRNN(nn.Module):\n",
        "#     def __init__(self, hidden_size, embed_size, output_size, dropout_p=0.1, SOS_TOKEN=0):\n",
        "#         super(AttentionDecoderRNN, self).__init__()\n",
        "#         self.embedding = nn.Embedding(output_size, embed_size)\n",
        "#         self.attention = Attention(hidden_size)\n",
        "#         self.gru = nn.GRU(embed_size + 2 * hidden_size, 2 * hidden_size, batch_first=True)  # Adjusted hidden size\n",
        "#         self.dense = nn.Linear(2 * hidden_size, output_size)  # Adjusted input size\n",
        "#         self.dropout = nn.Dropout(dropout_p)\n",
        "#         self.MAX_LENGTH = MAX_LENGTH\n",
        "#         self.SOS_TOKEN = SOS_TOKEN\n",
        "\n",
        "#     def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "#         B = encoder_outputs.size(0)\n",
        "#         decoder_input = torch.empty(B, 1, dtype=torch.long, device=device).fill_(self.SOS_TOKEN)\n",
        "#         decoder_hidden = encoder_hidden\n",
        "#         decoder_outputs = []\n",
        "#         attentions = []\n",
        "\n",
        "#         for i in range(self.MAX_LENGTH):\n",
        "#             embed = self.dropout(self.embedding(decoder_input))\n",
        "#             query = decoder_hidden.permute(1, 0, 2) # query: [1, B, hidden_size]\n",
        "#             context, attention_wt = self.attention(query, encoder_outputs)\n",
        "#             output, decoder_hidden = self.gru(torch.cat((embed, context), dim=2), decoder_hidden)\n",
        "#             output = self.dense(output)\n",
        "\n",
        "#             decoder_outputs.append(output)\n",
        "#             attentions.append(attention_wt)\n",
        "\n",
        "#             if target_tensor is not None:           # teacher_forcing\n",
        "#                 decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "#             else:                                   # autoregressive\n",
        "#                 _, topi = output.topk(1)\n",
        "#                 decoder_input = topi.squeeze(1).detach()\n",
        "\n",
        "#         decoder_outputs = F.log_softmax(torch.cat(decoder_outputs, dim=1), dim=-1)\n",
        "#         attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "#         return decoder_outputs, decoder_hidden, attentions"
      ],
      "metadata": {
        "id": "46q4wKFhQUQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL ARCHITECTURE"
      ],
      "metadata": {
        "id": "bYG0J5M6y9c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embed_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, embed_size)\n",
        "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input: (batch_size, seq_len)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        hidden = (hidden[0] + hidden[1]).unsqueeze(0)\n",
        "        # print(hidden.shape)\n",
        "        return output, hidden\n",
        "\n",
        "# based on Bahdanau et al. 2015\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W = nn.Linear(hidden_size, hidden_size)\n",
        "        # self.U = nn.Linear(hidden_size, hidden_size)\n",
        "        self.U = nn.Linear(2 * hidden_size, hidden_size)\n",
        "        self.V = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        # query: [batch_size, 1, hidden_size]\n",
        "        # keys: [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        scores = self.V(torch.tanh(self.W(query) + self.U(keys))) # scores: [batch_size, seq_len, 1]\n",
        "        scores = scores.squeeze(2).unsqueeze(1) # scores: [batch_size, 1, seq_len]\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys) # batch matrix multiplication\n",
        "        return context, weights\n",
        "\n",
        "class AttentionDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embed_size, output_size, dropout_p=0.1, SOS_TOKEN=1):\n",
        "        super(AttentionDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, embed_size)\n",
        "        self.attention = Attention(hidden_size)\n",
        "        # self.gru = nn.GRU(embed_size + hidden_size, hidden_size, batch_first=True)\n",
        "        self.gru = nn.GRU(embed_size + 2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.dense = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.SOS_TOKEN = SOS_TOKEN\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        B = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(B, 1, dtype=torch.long, device=device).fill_(self.SOS_TOKEN)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            embed = self.dropout(self.embedding(decoder_input))\n",
        "            query = decoder_hidden.permute(1, 0, 2) # query: [1, B, hidden_size]\n",
        "            context, attention_wt = self.attention(query, encoder_outputs)\n",
        "            output, decoder_hidden = self.gru(torch.cat((embed, context), dim=2), decoder_hidden)\n",
        "            output = self.dense(output)\n",
        "\n",
        "            decoder_outputs.append(output)\n",
        "            attentions.append(attention_wt)\n",
        "\n",
        "            if target_tensor is not None:           # teacher_forcing\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "            else:                                   # autoregressive\n",
        "                _, topi = output.topk(1)\n",
        "                decoder_input = topi.squeeze(1).detach()\n",
        "\n",
        "        decoder_outputs = F.log_softmax(torch.cat(decoder_outputs, dim=1), dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions"
      ],
      "metadata": {
        "id": "b4SCfl5jPmv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA LOADING"
      ],
      "metadata": {
        "id": "3b7hBsJ6zVvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataloading import prepare_indices, TranslationDataset"
      ],
      "metadata": {
        "id": "Aalq-_hnzM0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_be_src_i, en_be_trg_i = prepare_indices(en_lang, en_be_src, MAX_LENGTH), prepare_indices(be_lang, en_be_trg, MAX_LENGTH)\n",
        "en_gu_src_i, en_gu_trg_i = prepare_indices(en_lang, en_gu_src, MAX_LENGTH), prepare_indices(gu_lang, en_gu_trg, MAX_LENGTH)\n",
        "en_hi_src_i, en_hi_trg_i = prepare_indices(en_lang, en_hi_src, MAX_LENGTH), prepare_indices(hi_lang, en_hi_trg, MAX_LENGTH)\n",
        "en_ka_src_i, en_ka_trg_i = prepare_indices(en_lang, en_ka_src, MAX_LENGTH), prepare_indices(ka_lang, en_ka_trg, MAX_LENGTH)\n",
        "en_ma_src_i, en_ma_trg_i = prepare_indices(en_lang, en_ma_src, MAX_LENGTH), prepare_indices(ma_lang, en_ma_trg, MAX_LENGTH)\n",
        "en_ta_src_i, en_ta_trg_i = prepare_indices(en_lang, en_ta_src, MAX_LENGTH), prepare_indices(ta_lang, en_ta_trg, MAX_LENGTH)\n",
        "en_te_src_i, en_te_trg_i = prepare_indices(en_lang, en_te_src, MAX_LENGTH), prepare_indices(te_lang, en_te_trg, MAX_LENGTH)"
      ],
      "metadata": {
        "id": "ScsTbmvxzXqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING LOOP"
      ],
      "metadata": {
        "id": "CCtfU114zwLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for time estimation and %progressing\n",
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "def train_epoch(dataloader, encoder, decoder, encoder_optim, decoder_optim, criterion):\n",
        "    total_loss = 0\n",
        "    for i, data in enumerate(dataloader):\n",
        "        if (i + 1) % 400 == 0:\n",
        "            print(f\"Batch: {i + 1} / {len(dataloader)} loaded | Current Loss: {total_loss / (i + 1)}\")\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optim.zero_grad()\n",
        "        decoder_optim.zero_grad()\n",
        "\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_output, encoder_hidden, target_tensor)\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optim.step()\n",
        "        decoder_optim.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def train(dataloader, encoder, decoder, n_epochs, encoder_save_path, decoder_save_path, criterion, encoder_optim, decoder_optim):\n",
        "    start = time.time()\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        loss = train_epoch(dataloader, encoder, decoder, encoder_optim, decoder_optim, criterion)\n",
        "        print(f\"Epoch: {epoch + 1} / {n_epochs} | Loss: {loss}\")\n",
        "        print(f\"Time Elapsed: {timeSince(start, (epoch + 1) / n_epochs)}\")\n",
        "        losses.append(loss)\n",
        "        torch.save(encoder.state_dict(), encoder_save_path)\n",
        "        torch.save(decoder.state_dict(), decoder_save_path)\n",
        "\n",
        "    return losses"
      ],
      "metadata": {
        "id": "40xc9WxZzf0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ENGLISH-BENGALI"
      ],
      "metadata": {
        "id": "GUj_2SpFz8bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nk5hOJj0VDr",
        "outputId": "ae485691-7d01-431f-d355-0a0a452a06c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "en_be_dataset = TranslationDataset(en_lang, be_lang, en_be_src_i, en_be_trg_i, device)\n",
        "en_be_sampler = RandomSampler(en_be_dataset)\n",
        "en_be_dataloader = DataLoader(en_be_dataset, sampler=en_be_sampler, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "RPodArVC0xrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src, trg = next(iter(en_be_dataloader))\n",
        "src.shape, trg.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euEkDdl-OgcL",
        "outputId": "8ffa3432-a5ec-43ed-f353-2bf141900b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 40]), torch.Size([16, 40]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_SIZE = 256\n",
        "EMBED_SIZE = 512\n",
        "INPUT_SIZE = en_lang.n_words\n",
        "# OUTPUT_SIZE = hi_lang.n_words\n",
        "OUTPUT_SIZE = be_lang.n_words\n",
        "N_EPOCHS=10\n",
        "\n",
        "criterion = nn.NLLLoss(ignore_index=hi_lang.word2idx[\"<PAD>\"])\n",
        "encoder = EncoderRNN(INPUT_SIZE, EMBED_SIZE, HIDDEN_SIZE).to(device)\n",
        "decoder = AttentionDecoderRNN(HIDDEN_SIZE, EMBED_SIZE, OUTPUT_SIZE).to(device)\n",
        "encoder_optim = torch.optim.Adam(encoder.parameters())\n",
        "decoder_optim = torch.optim.Adam(decoder.parameters())\n",
        "\n",
        "# losses = train(en_hi_dataloader,\n",
        "#                encoder,\n",
        "#                decoder,\n",
        "#                N_EPOCHS,\n",
        "#                \"/content/drive/MyDrive/neural_machine_translation/iter4/saves/en_hi_lstm_attn_encoder_iter4.pth\",\n",
        "#                \"/content/drive/MyDrive/neural_machine_translation/iter4/saves/en_hi_lstm_attn_decoder_iter4.pth\",\n",
        "#                criterion,\n",
        "#                encoder_optim,\n",
        "#                decoder_optim\n",
        "# )\n",
        "\n",
        "encoder.load_state_dict(torch.load(\"/content/drive/MyDrive/neural_machine_translation/iter4/saves/en_hi_bigru_attn_encoder_iter4.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeZxq0Rwz6ke",
        "outputId": "cff160b5-975a-4d8d-a418-f92622f87102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = train(en_be_dataloader,\n",
        "               encoder,\n",
        "               decoder,\n",
        "               N_EPOCHS,\n",
        "               \"/content/drive/MyDrive/neural_machine_translation/iter4/saves/en_be_bigru_attn_encoder_iter4.pth\",\n",
        "               \"/content/drive/MyDrive/neural_machine_translation/iter4/saves/en_be_bigru_attn_decoder_iter4.pth\",\n",
        "               criterion,\n",
        "               encoder_optim,\n",
        "               decoder_optim\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLVpEiRUB__A",
        "outputId": "f152aab4-28b4-44e4-f629-d4d66de8d078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 400 / 4304 loaded | Current Loss: 7.569382841587067\n",
            "Batch: 800 / 4304 loaded | Current Loss: 7.207891881465912\n",
            "Batch: 1200 / 4304 loaded | Current Loss: 6.976794905265172\n",
            "Batch: 1600 / 4304 loaded | Current Loss: 6.8058427268266675\n",
            "Batch: 2000 / 4304 loaded | Current Loss: 6.669567894697189\n",
            "Batch: 2400 / 4304 loaded | Current Loss: 6.556768497029941\n",
            "Batch: 2800 / 4304 loaded | Current Loss: 6.464894703456333\n",
            "Batch: 3200 / 4304 loaded | Current Loss: 6.385794554948807\n",
            "Batch: 3600 / 4304 loaded | Current Loss: 6.313049903313319\n",
            "Batch: 4000 / 4304 loaded | Current Loss: 6.249852312803268\n",
            "Epoch: 1 / 10 | Loss: 6.20983701822483\n",
            "Time Elapsed: 23m 55s (- 215m 22s)\n",
            "Batch: 400 / 4304 loaded | Current Loss: 4.791704937219619\n",
            "Batch: 800 / 4304 loaded | Current Loss: 4.789106113612652\n",
            "Batch: 1200 / 4304 loaded | Current Loss: 4.8008152012030285\n",
            "Batch: 1600 / 4304 loaded | Current Loss: 4.794870827198029\n",
            "Batch: 2000 / 4304 loaded | Current Loss: 4.803681671380997\n",
            "Batch: 2400 / 4304 loaded | Current Loss: 4.804701784352462\n",
            "Batch: 2800 / 4304 loaded | Current Loss: 4.806278621809823\n",
            "Batch: 3200 / 4304 loaded | Current Loss: 4.804060682430864\n",
            "Batch: 3600 / 4304 loaded | Current Loss: 4.803327758312225\n",
            "Batch: 4000 / 4304 loaded | Current Loss: 4.8006852552890775\n",
            "Epoch: 2 / 10 | Loss: 4.803205979080891\n",
            "Time Elapsed: 47m 55s (- 191m 43s)\n",
            "Batch: 400 / 4304 loaded | Current Loss: 3.814119139909744\n",
            "Batch: 800 / 4304 loaded | Current Loss: 3.8412263745069506\n",
            "Batch: 1200 / 4304 loaded | Current Loss: 3.8690129830439886\n",
            "Batch: 1600 / 4304 loaded | Current Loss: 3.8962548303604128\n",
            "Batch: 2000 / 4304 loaded | Current Loss: 3.916909238100052\n",
            "Batch: 2400 / 4304 loaded | Current Loss: 3.9336344879865646\n",
            "Batch: 2800 / 4304 loaded | Current Loss: 3.9470317991290775\n",
            "Batch: 3200 / 4304 loaded | Current Loss: 3.963825342878699\n",
            "Batch: 3600 / 4304 loaded | Current Loss: 3.9792470586299897\n",
            "Batch: 4000 / 4304 loaded | Current Loss: 3.994328789830208\n",
            "Epoch: 3 / 10 | Loss: 4.001555197522543\n",
            "Time Elapsed: 71m 56s (- 167m 51s)\n",
            "Batch: 400 / 4304 loaded | Current Loss: 3.1475084048509596\n",
            "Batch: 800 / 4304 loaded | Current Loss: 3.178275777697563\n",
            "Batch: 1200 / 4304 loaded | Current Loss: 3.205467489759127\n",
            "Batch: 1600 / 4304 loaded | Current Loss: 3.240212600976229\n",
            "Batch: 2000 / 4304 loaded | Current Loss: 3.266370037674904\n",
            "Batch: 2400 / 4304 loaded | Current Loss: 3.2941862393418946\n",
            "Batch: 2800 / 4304 loaded | Current Loss: 3.318533069065639\n",
            "Batch: 3200 / 4304 loaded | Current Loss: 3.339475402161479\n",
            "Batch: 3600 / 4304 loaded | Current Loss: 3.359508966339959\n",
            "Batch: 4000 / 4304 loaded | Current Loss: 3.378488020002842\n",
            "Epoch: 4 / 10 | Loss: 3.392851740952761\n",
            "Time Elapsed: 95m 55s (- 143m 52s)\n",
            "Batch: 400 / 4304 loaded | Current Loss: 2.660346784591675\n",
            "Batch: 800 / 4304 loaded | Current Loss: 2.704776170551777\n",
            "Batch: 1200 / 4304 loaded | Current Loss: 2.7331005587180455\n",
            "Batch: 1600 / 4304 loaded | Current Loss: 2.759455753415823\n",
            "Batch: 2000 / 4304 loaded | Current Loss: 2.787909258246422\n",
            "Batch: 2400 / 4304 loaded | Current Loss: 2.8117892171939216\n",
            "Batch: 2800 / 4304 loaded | Current Loss: 2.835384952255658\n",
            "Batch: 3200 / 4304 loaded | Current Loss: 2.858911153972149\n",
            "Batch: 3600 / 4304 loaded | Current Loss: 2.8830799331267674\n",
            "Batch: 4000 / 4304 loaded | Current Loss: 2.9047224026918412\n",
            "Epoch: 5 / 10 | Loss: 2.920551917533006\n",
            "Time Elapsed: 119m 55s (- 119m 55s)\n",
            "Batch: 400 / 4304 loaded | Current Loss: 2.355584721267223\n",
            "Batch: 800 / 4304 loaded | Current Loss: 2.3818630467355253\n",
            "Batch: 1200 / 4304 loaded | Current Loss: 2.406006262501081\n",
            "Batch: 1600 / 4304 loaded | Current Loss: 2.433340340256691\n",
            "Batch: 2000 / 4304 loaded | Current Loss: 2.4595794949531555\n",
            "Batch: 2400 / 4304 loaded | Current Loss: 2.4850557604432106\n",
            "Batch: 2800 / 4304 loaded | Current Loss: 2.5099074698346002\n",
            "Batch: 3200 / 4304 loaded | Current Loss: 2.5337815511226656\n",
            "Batch: 3600 / 4304 loaded | Current Loss: 2.5552036208576627\n",
            "Batch: 4000 / 4304 loaded | Current Loss: 2.575870392203331\n",
            "Epoch: 6 / 10 | Loss: 2.5917206835624897\n",
            "Time Elapsed: 143m 53s (- 95m 55s)\n",
            "Batch: 400 / 4304 loaded | Current Loss: 2.1188476592302323\n",
            "Batch: 800 / 4304 loaded | Current Loss: 2.149277694821358\n",
            "Batch: 1200 / 4304 loaded | Current Loss: 2.1874572157859804\n",
            "Batch: 1600 / 4304 loaded | Current Loss: 2.2199061746150255\n",
            "Batch: 2000 / 4304 loaded | Current Loss: 2.2436245916485786\n",
            "Batch: 2400 / 4304 loaded | Current Loss: 2.270196690708399\n",
            "Batch: 2800 / 4304 loaded | Current Loss: 2.290574694744178\n",
            "Batch: 3200 / 4304 loaded | Current Loss: 2.314057725444436\n",
            "Batch: 3600 / 4304 loaded | Current Loss: 2.334146382510662\n",
            "Batch: 4000 / 4304 loaded | Current Loss: 2.3557636484801767\n",
            "Epoch: 7 / 10 | Loss: 2.3727021635298837\n",
            "Time Elapsed: 167m 55s (- 71m 58s)\n",
            "Batch: 400 / 4304 loaded | Current Loss: 1.9795031967759131\n",
            "Batch: 800 / 4304 loaded | Current Loss: 2.010612725317478\n",
            "Batch: 1200 / 4304 loaded | Current Loss: 2.0352327905098595\n",
            "Batch: 1600 / 4304 loaded | Current Loss: 2.0660504714399575\n",
            "Batch: 2000 / 4304 loaded | Current Loss: 2.0897442108392714\n",
            "Batch: 2400 / 4304 loaded | Current Loss: 2.11076345205307\n",
            "Batch: 2800 / 4304 loaded | Current Loss: 2.135183512185301\n",
            "Batch: 3200 / 4304 loaded | Current Loss: 2.1558549912273883\n",
            "Batch: 3600 / 4304 loaded | Current Loss: 2.1771440514922142\n",
            "Batch: 4000 / 4304 loaded | Current Loss: 2.1962221033573153\n",
            "Epoch: 8 / 10 | Loss: 2.2135159636961927\n",
            "Time Elapsed: 191m 55s (- 47m 58s)\n",
            "Batch: 400 / 4304 loaded | Current Loss: 1.856474444270134\n",
            "Batch: 800 / 4304 loaded | Current Loss: 1.882749978005886\n",
            "Batch: 1200 / 4304 loaded | Current Loss: 1.9081189705928168\n",
            "Batch: 1600 / 4304 loaded | Current Loss: 1.9351148165762424\n",
            "Batch: 2000 / 4304 loaded | Current Loss: 1.959323710143566\n",
            "Batch: 2400 / 4304 loaded | Current Loss: 1.9829028941194216\n",
            "Batch: 2800 / 4304 loaded | Current Loss: 2.0031632165397917\n",
            "Batch: 3200 / 4304 loaded | Current Loss: 2.0243278684839607\n",
            "Batch: 3600 / 4304 loaded | Current Loss: 2.046614597539107\n",
            "Batch: 4000 / 4304 loaded | Current Loss: 2.066355746626854\n",
            "Epoch: 9 / 10 | Loss: 2.0814451559491762\n",
            "Time Elapsed: 215m 53s (- 23m 59s)\n",
            "Batch: 400 / 4304 loaded | Current Loss: 1.7419683802127839\n",
            "Batch: 800 / 4304 loaded | Current Loss: 1.7725585953891276\n",
            "Batch: 1200 / 4304 loaded | Current Loss: 1.8016858347256979\n",
            "Batch: 1600 / 4304 loaded | Current Loss: 1.8306210607290268\n",
            "Batch: 2000 / 4304 loaded | Current Loss: 1.8547425904273986\n",
            "Batch: 2400 / 4304 loaded | Current Loss: 1.8785677941143513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EVALUATION"
      ],
      "metadata": {
        "id": "HV-MbJ3jCMkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"/content/drive/MyDrive/neural_machine_translation/val_data1.json\", \"rb\") as file:\n",
        "    val_data = json.load(file)\n",
        "en_be_eval = []\n",
        "en_be_id = []\n",
        "en_gu_eval = []\n",
        "en_gu_id = []\n",
        "en_hi_eval = []\n",
        "en_hi_id = []\n",
        "en_ka_eval = []\n",
        "en_ka_id = []\n",
        "en_ma_eval = []\n",
        "en_ma_id = []\n",
        "en_ta_eval = []\n",
        "en_ta_id = []\n",
        "en_te_eval = []\n",
        "en_te_id = []\n",
        "\n",
        "for lang_pair, data in val_data.items():\n",
        "    for _, d_entry in data.items():\n",
        "        for id, content in d_entry.items():\n",
        "            if lang_pair == \"English-Bengali\":\n",
        "                en_be_eval.append(content[\"source\"])\n",
        "                en_be_id.append(id)\n",
        "            elif lang_pair == \"English-Gujarati\":\n",
        "                en_gu_eval.append(content[\"source\"])\n",
        "                en_gu_id.append(id)\n",
        "            elif lang_pair == \"English-Hindi\":\n",
        "                en_hi_eval.append(content[\"source\"])\n",
        "                en_hi_id.append(id)\n",
        "            elif lang_pair == \"English-Kannada\":\n",
        "                en_ka_eval.append(content[\"source\"])\n",
        "                en_ka_id.append(id)\n",
        "            elif lang_pair == \"English-Malayalam\":\n",
        "                en_ma_eval.append(content[\"source\"])\n",
        "                en_ma_id.append(id)\n",
        "            elif lang_pair == \"English-Tamil\":\n",
        "                en_ta_eval.append(content[\"source\"])\n",
        "                en_ta_id.append(id)\n",
        "            elif lang_pair == \"English-Telgu\":\n",
        "                en_te_eval.append(content[\"source\"])\n",
        "                en_te_id.append(id)\n",
        "\n",
        "# en_be_src, en_be_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/val_data1.json\", \"English-Bengali\")\n",
        "# en_hi_src, en_hi_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/val_data1.json\", \"English-Hindi\")\n",
        "# en_gu_src, en_gu_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/val_data1.json\", \"English-Gujarati\")\n",
        "# en_ka_src, en_ka_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/val_data1.json\", \"English-Kannada\")\n",
        "# en_ma_src, en_ma_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/val_data1.json\", \"English-Malayalam\")\n",
        "# en_ta_src, en_ta_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/val_data1.json\", \"English-Tamil\")\n",
        "# en_te_src, en_te_trg = retrieve_sents(\"/content/drive/MyDrive/neural_machine_translation/val_data1.json\", \"English-Telgu\")\n",
        "\n",
        "en_be_src = [english_preprocess(sent) for sent in en_be_src]\n",
        "en_hi_src = [english_preprocess(sent) for sent in en_hi_src]\n",
        "en_ka_src = [english_preprocess(sent) for sent in en_ka_src]\n",
        "en_ma_src = [english_preprocess(sent) for sent in en_ma_src]\n",
        "en_gu_src = [english_preprocess(sent) for sent in en_gu_src]\n",
        "en_ta_src = [english_preprocess(sent) for sent in en_ta_src]\n",
        "en_te_src = [english_preprocess(sent) for sent in en_te_src]"
      ],
      "metadata": {
        "id": "3s0N8EtVCMDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model\n",
        "encoder.load_state_dict(torch.load(\"/content/drive/MyDrive/neural_machine_translation/iter4/saves/en_be_bigru_attn_encoder_iter4.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"/content/drive/MyDrive/neural_machine_translation/iter4/saves/en_be_bigru_attn_decoder_iter4.pth\"))"
      ],
      "metadata": {
        "id": "4KcxQuCjCRDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = lang.sentence_to_indices(sentence)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def evaluate(encoder, decoder, src_sents, src_lang, trg_lang, EOS_TOKEN=1):\n",
        "  with torch.no_grad():\n",
        "\n",
        "    trg_sents = []\n",
        "\n",
        "    for i, src_sent in enumerate(src_sents):\n",
        "      if i % 1000 == 0:\n",
        "        print(f\"Number of sentences translated: {i}\")\n",
        "      input_tensor = tensorFromSentence(src_lang, src_sent)\n",
        "      encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "      decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "      _, topi = decoder_outputs.topk(1)\n",
        "      decoded_ids = topi.squeeze()\n",
        "\n",
        "      decoded_words = []\n",
        "\n",
        "      for idx in decoded_ids:\n",
        "        if idx.item() == EOS_TOKEN:\n",
        "          break\n",
        "        decoded_words.append(trg_lang.idx2word[idx.item()])\n",
        "\n",
        "      trg_sents.append(\" \".join(decoded_words))\n",
        "\n",
        "    return trg_sents"
      ],
      "metadata": {
        "id": "AHCSF1fKCpg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_be_trans = evaluate(encoder, decoder, en_be_eval, en_lang, be_lang)"
      ],
      "metadata": {
        "id": "FuNHuG5aCs_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(en_be_eval), len(en_be_trans)"
      ],
      "metadata": {
        "id": "tqNcY9jdCv7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'ID': en_be_id, 'Translation': en_be_trans})\n",
        "csv_path = \"/content/drive/MyDrive/neural_machine_translation/iter4/bengali.csv\"\n",
        "df.to_csv(csv_path, index=False)"
      ],
      "metadata": {
        "id": "TX3qhSZaRQXY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![seq2seq_rnn](./images/seq_2_seq_rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "class Language:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<SOS>\", 1: \"<EOS>\"}\n",
    "        self.n_words = 2 \n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sentences(df: pd.DataFrame, lang: str) -> pd.Series:\n",
    "    sentence = df[lang].str.lower()\n",
    "    sentence = sentence.str.replace('[^a-zäöüß\\s]+', '', regex=True)\n",
    "    sentence = sentence.apply(lambda x: unicodedata.normalize('NFD', x))\n",
    "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    return sentence\n",
    "\n",
    "def read_sentences(df, lang1, lang2):\n",
    "    sentence1 = normalize_sentences(df, lang1)\n",
    "    sentence2 = normalize_sentences(df, lang2)\n",
    "    return sentence1, sentence2\n",
    "\n",
    "# def read_file(loc, lang1, lang2):\n",
    "#    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2])\n",
    "#    return df\n",
    "\n",
    "def read_file(loc, lang1, lang2):\n",
    "    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2, 'metadata'])\n",
    "    df = df[[lang1, lang2]] \n",
    "    # print(df.head())\n",
    "    return df\n",
    "\n",
    "def process_data(lang1, lang2):\n",
    "    df = read_file('data/%s-%s.txt' % (lang1, lang2), lang1, lang2)\n",
    "    sentence1, sentence2 = read_sentences(df, lang1, lang2)\n",
    "    source = Language()\n",
    "    target = Language()\n",
    "    pairs = []\n",
    "    for i in range(len(df)):\n",
    "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
    "            source.add_sentence(sentence1[i])\n",
    "            target.add_sentence(sentence2[i])\n",
    "            pairs.append([sentence1[i], sentence2[i]])\n",
    "    return source, target, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_from_sentences(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensor_from_sentences(lang, sentence):\n",
    "    idx = idx_from_sentences(lang, sentence)\n",
    "    idx.append(EOS_token)\n",
    "    return torch.tensor(idx, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensors_from_pair(pair, source, target):\n",
    "    source_tensor = tensor_from_sentences(source, pair[0])\n",
    "    target_tensor = tensor_from_sentences(target, pair[1])\n",
    "    return (source_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embed_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, num_layers)\n",
    "    \n",
    "    def forward(self, source):\n",
    "        embedded = self.embedding(source)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, embbed_dim)\n",
    "        self.rnn = nn.GRU(embbed_dim, hidden_dim, num_layers)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = input.view(1, -1)\n",
    "        embedded = F.relu(self.embedding(input))\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        prediction = self.softmax(self.fc_out(output[0]))\n",
    "\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.65):\n",
    "        # input_length = source.size(0)\n",
    "        # target_length = target.shape[0]\n",
    "        # batch_size = target.shape[1]\n",
    "        # vocab_size = self.decoder.output_dim\n",
    "        # outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
    "        \n",
    "        # for i in range(input_length):\n",
    "        #     encoder_output, encoder_hidden = self.encoder(source[i])\n",
    "\n",
    "        # decoder_hidden = encoder_hidden.to(self.device)\n",
    "        # decoder_input = torch.tensor([[SOS_token]], device=self.device)\n",
    "\n",
    "        # for t in range(target_length):\n",
    "        #     decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "        #     outputs[t] = decoder_output\n",
    "        #     teacher_force = random.random() < teacher_forcing_ratio\n",
    "        #     topv, topi = decoder_output.topk(1)\n",
    "        #     input = (target[t] if teacher_force else topi)\n",
    "        #     if teacher_force == False and input.item() == EOS_token:\n",
    "        #         break\n",
    "\n",
    "        # return outputs\n",
    "        batch_size = source.size(1)\n",
    "        target_length = target.shape[0]\n",
    "        vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
    "        \n",
    "        encoder_output, encoder_hidden = self.encoder(source)\n",
    "        \n",
    "        decoder_input = torch.tensor([SOS_token for _ in range(batch_size)], device=self.device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        for t in range(target_length):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input.unsqueeze(0), decoder_hidden)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = decoder_output.argmax(1) \n",
    "            decoder_input = target[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clac_model(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
    "    model_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    loss = 0\n",
    "    epoch_loss = 0\n",
    "    output = model(input_tensor, target_tensor)\n",
    "    num_iter = output.size(0)\n",
    "    for i in range(num_iter):\n",
    "        loss += criterion(output[i], target_tensor[i])\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    epoch_loss = loss.item() / num_iter\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, source, target, pairs, num_iterations=20000):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss = 0\n",
    "    training_pairs = [tensors_from_pair(random.choice(pairs), source, target) for i in range(num_iterations)]\n",
    "    for iter in range(1, num_iterations + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = clac_model(model, input_tensor, target_tensor, optimizer, criterion)\n",
    "        total_loss += loss\n",
    "        if iter % 1000 == 0:\n",
    "            print('iter: %d, loss: %.4f' % (iter, total_loss / 1000))\n",
    "            total_loss = 0\n",
    "\n",
    "    torch.save(model.state_dict(), 'model/seq2seq_rnn.pt')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, input_lang, output_lang, sentences, MAX_LENGTH=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensor_from_sentences(input_lang, sentences[0])\n",
    "        output_tensor = tensor_from_sentences(output_lang, sentences[1])\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        output = model(input_tensor, output_tensor)\n",
    "        for i in range(output.size(0)):\n",
    "            topv, topi = output[i].topk(1)\n",
    "            if topi[0].item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly(model, source, target, pairs, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('source: {}'.format(pair[0]))\n",
    "        print('target: {}'.format(pair[1]))\n",
    "        output_words = evaluate(model, source, target, pair)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('predicted: {}'.format(output_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sentence ['it wasnt there the last time', 'ich war das letztemal nicht da']\n"
     ]
    }
   ],
   "source": [
    "lang1 = 'deu'\n",
    "lang2 = 'eng'\n",
    "\n",
    "source, target, pairs = process_data(lang1, lang2)\n",
    "randomize = random.choice(pairs)\n",
    "print('random sentence {}'.format(randomize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : 17136 Output : 36887\n"
     ]
    }
   ],
   "source": [
    "input_size = source.n_words\n",
    "output_size = target.n_words\n",
    "\n",
    "print('Input : {} Output : {}'.format(input_size, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "num_iters = 20000\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
    "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(17136, 256)\n",
      "  (rnn): GRU(256, 512, num_layers=2)\n",
      ")\n",
      "Decoder(\n",
      "  (embedding): Embedding(36887, 256)\n",
      "  (rnn): GRU(256, 512, num_layers=2)\n",
      "  (fc_out): Linear(in_features=512, out_features=36887, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1000, loss: 6.7308\n",
      "iter: 2000, loss: 6.0124\n",
      "iter: 3000, loss: 5.7154\n",
      "iter: 4000, loss: 5.4805\n",
      "iter: 5000, loss: 5.3974\n",
      "iter: 6000, loss: 5.2438\n",
      "iter: 7000, loss: 5.1878\n",
      "iter: 8000, loss: 5.0264\n",
      "iter: 9000, loss: 4.9978\n",
      "iter: 10000, loss: 4.9237\n",
      "iter: 11000, loss: 4.9163\n",
      "iter: 12000, loss: 4.9442\n",
      "iter: 13000, loss: 4.7817\n",
      "iter: 14000, loss: 4.7696\n",
      "iter: 15000, loss: 4.7943\n",
      "iter: 16000, loss: 4.7372\n",
      "iter: 17000, loss: 4.7128\n",
      "iter: 18000, loss: 4.6624\n",
      "iter: 19000, loss: 4.6618\n",
      "iter: 20000, loss: 4.6184\n"
     ]
    }
   ],
   "source": [
    "model = train(model, source, target, pairs, num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: everybody likes you\n",
      "target: alle mogen dich\n",
      "predicted: siehst du ihnen dich\n",
      "source: stand up\n",
      "target: stehen sie auf\n",
      "predicted: ich werde mich <EOS>\n",
      "source: i wont likely go to boston\n",
      "target: nach boston gehe ich wohl nicht\n",
      "predicted: ich werde nicht nicht boston gehen boston\n",
      "source: when does tom get here\n",
      "target: wann wird tom hier sein\n",
      "predicted: wann wann tom wann <EOS>\n",
      "source: tom never loses his cool\n",
      "target: tom verliert nie die fassung\n",
      "predicted: tom setzte nie nie nie <EOS>\n",
      "source: how do you prevent back pain\n",
      "target: wie verhindert man ruckenschmerzen\n",
      "predicted: wie haltst du das <EOS>\n",
      "source: tom is home\n",
      "target: tom ist zu hause\n",
      "predicted: tom ist hause hause <EOS>\n",
      "source: theyre having extreme money problems\n",
      "target: sie haben heftige geldprobleme\n",
      "predicted: sie geld geld geld <EOS>\n",
      "source: tom puts a lot of sugar and cream in his coffee\n",
      "target: tom trinkt seinen kaffee mit viel zucker und sahne\n",
      "predicted: tom und einer und kaffee einen in und sein kaffee\n",
      "source: we thought you knew\n",
      "target: wir dachten sie wussten es\n",
      "predicted: wir haben du fur <EOS>\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(model, source, target, pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
